{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60428c3-1774-40a3-b303-0b8b2386dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75305410-fb2c-4b8f-8ee5-33392d2b40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Set the API key in the environment\n",
    "os.environ[\"POSTGRES_USERNAME\"] = \"alifiya.kanpurwala.24@ucl.ac.uk\"\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = \"ZKgioL\"\n",
    "os.environ[\"POSTGRES_SCHEMA\"] = \"schema_alifiyakanpurwala24uclacuk\"\n",
    "\n",
    "os.environ['MONGODB_PASSWORD'] = 'io8OKNKlqOk79hLv'\n",
    "os.environ['POLYGON_API_KEY'] = '25ilKx91RSsS8wO7yGQO66OmNR5CxoIu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96c9d5b-3d1b-453d-ba05-e2f96e779711",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MongoClient\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54695103-65d0-4635-b918-5dda81803138",
   "metadata": {},
   "source": [
    "## Database Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ae34b-c091-4fd9-8759-c2ca4e0a9bf5",
   "metadata": {},
   "source": [
    "### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7187c70-ff66-4faf-828e-2ab4319f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create PostgreSQL connection string\n",
    "pg_conn_string = f\"postgresql+psycopg2://{os.getenv('POSTGRES_USERNAME')}:{os.getenv('POSTGRES_PASSWORD')}@{\"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\"}:{5432}/{\"postgres\"}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "pg_engine = create_engine(pg_conn_string, connect_args={\"options\": f\"-c search_path={os.getenv('POSTGRES_SCHEMA')}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333649a-df91-4bed-b571-ac908c9f47a4",
   "metadata": {},
   "source": [
    "### Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa844ae-e628-4bb6-837e-4186fc6c9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/?retryWrites=true&w=majority&appName=ucl-de\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['ucl-de']\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca7a04-e79b-444b-8bad-a3db5dd5dd7c",
   "metadata": {},
   "source": [
    "## Stock Market Data - SQL/DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4113c96d-7f6d-49fc-a667-08cff8145cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNVDA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMZN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOGL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAVGO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBRK-B\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Download historical data for 2024\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_stock \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(tickers, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-12-31\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Reset the index to make the date a column and flatten the MultiIndex columns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df_stock\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(col)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_stock\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_flat_index()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yf' is not defined"
     ]
    }
   ],
   "source": [
    "# Getting Stock Data for S&P ETF & Top 10 Companies for 2024-01-01 to 2024-12-31\n",
    "# Define the ticker symbols\n",
    "tickers = ['SPY', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'META', 'GOOGL', 'TSLA', 'AVGO', 'GOOG', 'BRK-B']\n",
    "\n",
    "# Download historical data for 2024\n",
    "df_stock = yf.download(tickers, start=\"2024-01-01\", end=\"2024-12-31\")\n",
    "\n",
    "# Reset the index to make the date a column and flatten the MultiIndex columns\n",
    "df_stock.columns = ['_'.join(col).strip() for col in df_stock.columns.to_flat_index()]\n",
    "df_stock.reset_index(inplace=True)\n",
    "\n",
    "# Unpivot the DataFrame while keeping columns for 'Date' and 'Symbol'\n",
    "df_stock = df_stock.melt(id_vars=['Date'], var_name='Symbol_Price', value_name='Value')\n",
    "\n",
    "# Extract 'Symbol' and 'Price' from the 'Symbol_Price' column\n",
    "df_stock[['Price', 'Symbol']] = df_stock['Symbol_Price'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the 'Symbol_Price' column\n",
    "df_stock.drop(columns=['Symbol_Price'], inplace=True)\n",
    "\n",
    "# Pivot the table to create a wide format with columns for High, Low, Open, Close, Volume\n",
    "df_stock = df_stock.pivot_table(index=['Date', 'Symbol'], columns='Price', values='Value', aggfunc='first')\n",
    "\n",
    "# Reset the index to flatten the result\n",
    "df_stock.reset_index(inplace=True)\n",
    "\n",
    "# Save the DataFrame to PostgreSQL as 'stock_data' table\n",
    "df_stock.to_sql('stock_data', pg_engine, if_exists='replace', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e54d1a-8b5a-44ef-a703-d0cdabad9e90",
   "metadata": {},
   "source": [
    "## Crypto Data - NoSQL/JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff843d9a-5732-4728-bf61-ff01001f38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coin_data(coin_names):\n",
    "    for coin_name in coin_names:\n",
    "        # Base URL for Polygon.io API\n",
    "        url = 'https://api.polygon.io/v2/aggs/ticker/X:'+coin_name+'USD/range/1/day/2024-01-01/2024-12-31'\n",
    "        \n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url, params={'apiKey': os.getenv('POLYGON_API_KEY')})\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(coin_name)\n",
    "            print(data['results'][0])\n",
    "            # Extract the 'results' JSON and rename fields\n",
    "            data_to_save = [{\n",
    "                'volume': result['v'],\n",
    "                'volume_weighted': result['vw'],\n",
    "                'open': result['o'],\n",
    "                'close': result['c'],\n",
    "                'high': result['h'],\n",
    "                'low': result['l'],\n",
    "                'timestamp': pd.to_datetime(result['t'], unit='ms'),\n",
    "                'num_trades': result['n'],\n",
    "                'coin_name': coin_name  # Add the coin_name field\n",
    "            } for result in data['results']]     \n",
    "\n",
    "            # Connect to MongoDB and insert the documents\n",
    "            collection = db['crypto_data']\n",
    "            collection.insert_many(data_to_save)\n",
    "            print(\"Documents inserted successfully.\")\n",
    "        else:\n",
    "            print(f\"Error fetching data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7fbb4-18d3-4aca-a2ac-a861f5a3730f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Note:</strong> Only five (5) requests a minute so two loops for 10.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4d9ecf-f34c-4c40-b9ce-cc1b5a68538c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m coin_names_1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBTC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXRP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOGE\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_coin_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoin_names_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mget_coin_data\u001b[0;34m(coin_names)\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.polygon.io/v2/aggs/ticker/X:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcoin_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSD/range/1/day/2024-01-01/2024-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Send a GET request to the API\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapiKey\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLYGON_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)})\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "coin_names_1 = {\"BTC\", \"ETH\", \"XRP\", \"SOL\", \"DOGE\"}\n",
    "get_coin_data(coin_names_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a342e-36fd-4870-96cc-a0bbe9b9b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_names_2 = {\"ADA\", \"TRX\", \"XLM\", \"AVAX\", \"SHIB\"}\n",
    "get_coin_data(coin_names_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab12f2-baca-4db7-a7b2-a4645111a299",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c34fdc-18c8-48a0-8e07-9773849815b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Code Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab955f01-abea-42e0-9a26-c25ce5b11a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'crypto_posts.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open and read the JSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrypto_posts.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize an empty list to store the formatted data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'crypto_posts.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('crypto_posts.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize an empty list to store the formatted data\n",
    "crypto_posts = []\n",
    "\n",
    "# Get the keys of the timestamp and post data dynamically\n",
    "timestamp_keys = data.get('timestamp', {}).keys()\n",
    "post_keys = data.get('post', {}).keys()\n",
    "\n",
    "# We will assume both 'timestamp' and 'post' have the same keys\n",
    "# Loop through all available keys\n",
    "for key in timestamp_keys:\n",
    "    # Dynamically create a dictionary combining values from timestamp and post for each key\n",
    "    crypto_posts.append({\n",
    "        **{field: data[field].get(key, '') for field in data if isinstance(data[field], dict)},\n",
    "    })\n",
    "\n",
    "# Print the structured output\n",
    "# print(json.dumps(crypto_posts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b289faf-96e1-43a6-b312-b13424dbee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MongoDB connection\n",
    "# Other parts already set above\n",
    "collection = db['crypto_posts']  # Replace with your collection name\n",
    "\n",
    "# Insert the data into the collection\n",
    "collection.insert_many(crypto_posts)\n",
    "\n",
    "# Check if data is saved by querying the collection\n",
    "saved_data = collection.find().limit(5)  # Get the first 5 documents for verification\n",
    "\n",
    "# Print out the saved data\n",
    "for document in saved_data:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c46e2-d0cb-456a-b89c-c591c7de97f7",
   "metadata": {},
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9788d448-f71a-4dd6-b80c-11a3961b9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "mongo_package_name = \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\"\n",
    "postgress_package_name = \"org.postgresql:postgresql:42.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284ceb8a-2553-4d24-8278-55cddd6fc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.5.4-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dd3f9adb-0ceb-4c26-a32d-59d444f36761;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.3.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 928ms :: artifacts dl 129ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.postgresql#postgresql;42.3.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dd3f9adb-0ceb-4c26-a32d-59d444f36761\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/37ms)\n",
      "25/03/10 15:55:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\", f\"{postgress_package_name},{mongo_package_name}\") \\\n",
    "    .appName(\"PostgresMongo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4f917-6333-400e-8a31-891eace66b72",
   "metadata": {},
   "source": [
    "### Getting from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50460bc1-a70e-492e-99a5-cf9aae40ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "|               Date|Symbol|             Close|              High|               Low|              Open|   Volume|\n",
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "|2024-01-02 00:00:00|  AAPL|184.53208923339844|187.31538170646215|182.79253333369908|186.03307200647276|8.24887E7|\n",
      "|2024-01-02 00:00:00|  AMZN|149.92999267578125| 152.3800048828125|148.38999938964844| 151.5399932861328|4.73394E7|\n",
      "|2024-01-02 00:00:00|  AVGO|107.09550476074219|108.73541136554675|106.27752002980789|107.76054315701123| 2.8831E7|\n",
      "|2024-01-02 00:00:00| BRK-B| 362.4599914550781|362.57000732421875|355.94000244140625|356.32000732421875|4737000.0|\n",
      "|2024-01-02 00:00:00|  GOOG|139.06033325195312|    140.1115639594|137.24685727343498|139.10019855495605|2.00719E7|\n",
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL connection details\n",
    "pg_url = f\"jdbc:postgresql://uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com:5432/postgres\"\n",
    "pg_properties = {\n",
    "    \"user\": os.getenv(\"POSTGRES_USERNAME\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"searchpath\": os.getenv(\"POSTGRES_SCHEMA\")  # Optional, specify schema if necessary\n",
    "}\n",
    "\n",
    "# Define the table name\n",
    "table_name = \"stock_data\"  # Replace with your table name\n",
    "\n",
    "# Form the SQL query\n",
    "query = f\"SELECT * FROM {os.getenv(\"POSTGRES_SCHEMA\")}.{table_name}\"\n",
    "\n",
    "# Load data from PostgreSQL into Spark DataFrame\n",
    "df_stocks = spark.read.jdbc(url=pg_url, table=f\"({query}) as query\", properties=pg_properties)\n",
    "\n",
    "# Show the first 5 rows of the dataframe\n",
    "df_stocks.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4d94c-5a17-44f2-9047-f1188fe6827f",
   "metadata": {},
   "source": [
    "### Getting from Mongo - Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a28cee8-8596-465c-902d-d0986584e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "| close|coin_name|  high|   low|num_trades|  open|          timestamp|            volume|volume_weighted|\n",
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "|110.11|      SOL|110.44|101.47|    108681| 101.7|2024-01-01 00:00:00| 1626237.539067202|       105.8227|\n",
      "|106.74|      SOL|117.03| 106.0|    200857| 109.9|2024-01-02 00:00:00|2735152.6783066373|       111.1942|\n",
      "| 98.59|      SOL|110.04|  71.0|    276745|106.77|2024-01-03 00:00:00|4241949.4304016875|        99.1378|\n",
      "|105.01|      SOL|108.26| 96.67|    156567| 98.57|2024-01-04 00:00:00|2364126.5787030575|       102.6787|\n",
      "|100.02|      SOL|105.57| 95.33|    155260|105.01|2024-01-05 00:00:00|2027948.8000170968|        99.8606|\n",
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_crypto = spark.read.format(\"mongo\").option(\"uri\", \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/ucl-de.crypto_data?retryWrites=true&w=majority\").load()\n",
    "df_crypto = df_crypto.drop(\"_id\")\n",
    "df_crypto.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15fee1-f040-4fd9-859f-a3f0d1e56669",
   "metadata": {},
   "source": [
    "### Getting from Mongo - Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3bcd11d-46ae-4e50-82df-5ff67ec5d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "|        cleaned_post|    polarity|                post|             subject|subjectivity|subsection| timestamp|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "|You've been holdi...|0.1353333333|You've been holdi...|Has Bitcoin met y...|0.5226666667|       BTC|2024-11-05|\n",
      "|Bitcoin has indee...|0.1534090909|Bitcoin has indee...|Has Bitcoin met y...|0.5629734848|       BTC|2024-11-05|\n",
      "|I would say Bitco...|0.4083333333|I would say Bitco...|Has Bitcoin met y...|0.3444444444|       BTC|2024-11-05|\n",
      "|My question to yo...|0.0798611111|Quote from: David...|Has Bitcoin met y...|0.5534722222|       BTC|2024-11-05|\n",
      "|You've been holdi...|0.0408333333|Quote from: David...|Has Bitcoin met y...|0.3734259259|       BTC|2024-11-05|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posts = spark.read.format(\"mongo\").option(\"uri\", \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/ucl-de.crypto_posts?retryWrites=true&w=majority\").load()\n",
    "df_posts = df_posts.drop(\"_id\")\n",
    "df_posts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce78684-b26d-4af3-ba63-d8e65cd860b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "|        cleaned_post|    polarity|                post|             subject|subjectivity|subsection|          timestamp|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "|You've been holdi...|0.1353333333|You've been holdi...|Has Bitcoin met y...|0.5226666667|       BTC|2024-11-05 00:00:00|\n",
      "|Bitcoin has indee...|0.1534090909|Bitcoin has indee...|Has Bitcoin met y...|0.5629734848|       BTC|2024-11-05 00:00:00|\n",
      "|I would say Bitco...|0.4083333333|I would say Bitco...|Has Bitcoin met y...|0.3444444444|       BTC|2024-11-05 00:00:00|\n",
      "|My question to yo...|0.0798611111|Quote from: David...|Has Bitcoin met y...|0.5534722222|       BTC|2024-11-05 00:00:00|\n",
      "|You've been holdi...|0.0408333333|Quote from: David...|Has Bitcoin met y...|0.3734259259|       BTC|2024-11-05 00:00:00|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cast 'timestamp' column to TIMESTAMP type if it's in string format\n",
    "df_posts = df_posts.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "# Now show the updated dataframe\n",
    "df_posts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86680d55-6f1d-4a36-a3ac-44a035972eae",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875d9e1-090b-48ec-bc4a-089f227eb638",
   "metadata": {},
   "source": [
    "### 1. Understandng Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ae081f-f5a6-4b78-90c0-1b42fe8f03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n",
    "df_posts.createOrReplaceTempView(\"posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df7d6d9-30cb-4a29-a2f3-37248ff54785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|      2761|2024-01-02 00:00:00|2024-12-30 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(Date) AS start_date,\n",
    "        MAX(Date) AS end_date\n",
    "    FROM stocks\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1045366-499d-4e55-b2e7-e079e1f8b77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|     40626|2024-01-01 00:00:00|2024-12-31 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(timestamp) AS start_date,\n",
    "        MAX(timestamp) AS end_date\n",
    "    FROM crypto\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef2fdcf-63d6-4e7f-a00e-748eb62aa5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|      1432|2010-10-19 00:00:00|2024-12-30 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(CAST(timestamp AS TIMESTAMP)) AS start_date,\n",
    "        MAX(CAST(timestamp AS TIMESTAMP)) AS end_date\n",
    "    FROM posts\n",
    "    WHERE timestamp IS NOT NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5aaea-93ec-4c08-bf32-040370697783",
   "metadata": {},
   "source": [
    "##### Data Coverage Summary\n",
    "\n",
    "We begin by inspecting the time range and volume of records across our three datasets:\n",
    "\n",
    "- **Stocks**: 2,761 records spanning from **2024-01-02** to **2024-12-30** — confirms near-daily entries across multiple companies for a full year.\n",
    "- **Crypto**: 40,626 records from **2024-01-01** to **2024-12-31** — much higher frequency, likely due to daily data across multiple coins.\n",
    "- **Posts**: 1,432 sentiment-tagged posts ranging from **2010-10-19** to **2024-12-30** — though historical, we'll likely focus on 2024 to align with price data.\n",
    "This confirms all datasets have overlapping coverage for **2024**, making them suitable for correlation and trend analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8cf9b-e59b-4780-81a2-914cde292dfd",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis\n",
    "#### 2.1 Top traded stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbee5610-9a5c-4914-b315-c0353f6ecab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Symbol|total_traded_volume|\n",
      "+------+-------------------+\n",
      "|  NVDA|       9.4937251E10|\n",
      "|  TSLA|      2.38213787E10|\n",
      "|   SPY|      1.44110064E10|\n",
      "|  AAPL|      1.43565874E10|\n",
      "|  AMZN|      1.03029356E10|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Top traded stocks\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol, SUM(Volume) AS total_traded_volume\n",
    "    FROM stocks\n",
    "    GROUP BY Symbol\n",
    "    ORDER BY total_traded_volume DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e94d7b0-b470-400c-b9d3-6e396b2a7dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|coin_name| total_traded_volume|\n",
      "+---------+--------------------+\n",
      "|     DOGE|3.473064391563710...|\n",
      "|      XRP|6.971414891211105E11|\n",
      "|      ADA|1.159059070260934...|\n",
      "|      XLM|7.916427541607889E10|\n",
      "|      TRX|2.149682109878055...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Top traded crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name, SUM(volume) AS total_traded_volume\n",
    "    FROM crypto\n",
    "    GROUP BY coin_name\n",
    "    ORDER BY total_traded_volume DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673c1ad-c87f-4730-88f6-d429f685eaee",
   "metadata": {},
   "source": [
    "#### 2.2 Daily Price Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade3b9a7-7aa8-41a5-b8f0-42356d00e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+\n",
      "|Symbol|               Date|         price_gap|\n",
      "+------+-------------------+------------------+\n",
      "|  AAPL|2024-01-02 00:00:00| 4.522848372763065|\n",
      "|  AMZN|2024-01-02 00:00:00|3.9900054931640625|\n",
      "|  AVGO|2024-01-02 00:00:00|2.4578913357388643|\n",
      "| BRK-B|2024-01-02 00:00:00|   6.6300048828125|\n",
      "|  GOOG|2024-01-02 00:00:00| 2.864706685965018|\n",
      "| GOOGL|2024-01-02 00:00:00| 2.959273593909728|\n",
      "|  META|2024-01-02 00:00:00|13.099953782164846|\n",
      "|  MSFT|2024-01-02 00:00:00| 9.044104012460366|\n",
      "|  NVDA|2024-01-02 00:00:00|1.6995150988554357|\n",
      "|   SPY|2024-01-02 00:00:00|3.1397485945930157|\n",
      "|  TSLA|2024-01-02 00:00:00| 6.839996337890625|\n",
      "|  AAPL|2024-01-03 00:00:00| 2.435390462707147|\n",
      "|  AMZN|2024-01-03 00:00:00| 2.720001220703125|\n",
      "|  AVGO|2024-01-03 00:00:00|1.9428331710988118|\n",
      "| BRK-B|2024-01-03 00:00:00| 6.779998779296875|\n",
      "|  GOOG|2024-01-03 00:00:00| 2.650480301344345|\n",
      "| GOOGL|2024-01-03 00:00:00|2.5407923261034284|\n",
      "|  META|2024-01-03 00:00:00|  4.75186803970297|\n",
      "|  MSFT|2024-01-03 00:00:00|4.7053088974220145|\n",
      "|  NVDA|2024-01-03 00:00:00|0.8637535543833152|\n",
      "+------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In stocks\n",
    "spark.sql(\"\"\"\n",
    "   SELECT Symbol, Date, (High - Low) AS price_gap \n",
    "   FROM stocks\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59abb02f-ff61-4537-9ff6-658ee22d6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------------+\n",
      "|coin_name|      date|         price_gap|\n",
      "+---------+----------+------------------+\n",
      "|      SOL|2024-01-01| 8.969999999999999|\n",
      "|      SOL|2024-01-02|11.030000000000001|\n",
      "|      SOL|2024-01-03|39.040000000000006|\n",
      "|      SOL|2024-01-04|11.590000000000003|\n",
      "|      SOL|2024-01-05|10.239999999999995|\n",
      "|      SOL|2024-01-06| 8.820000000000007|\n",
      "|      SOL|2024-01-07|  9.22999999999999|\n",
      "|      SOL|2024-01-08|16.049999999999997|\n",
      "|      SOL|2024-01-09|13.260000000000005|\n",
      "|      SOL|2024-01-10|13.530000000000001|\n",
      "|      SOL|2024-01-11|              9.75|\n",
      "|      SOL|2024-01-12|14.227999999999994|\n",
      "|      SOL|2024-01-13| 8.010000000000005|\n",
      "|      SOL|2024-01-14|11.829999999999998|\n",
      "|      SOL|2024-01-15|3.9680000000000035|\n",
      "|      SOL|2024-01-16| 4.658000000000001|\n",
      "|      SOL|2024-01-17|6.6299999999999955|\n",
      "|      SOL|2024-01-18|12.189999999999998|\n",
      "|      SOL|2024-01-19| 8.599999999999994|\n",
      "|      SOL|2024-01-20| 4.879000000000005|\n",
      "+---------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Crypto\n",
    "spark.sql(\"\"\"\n",
    "   SELECT coin_name, DATE(timestamp) AS date, (high - low) AS price_gap\n",
    "   FROM crypto\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654578f-652c-4619-9f10-75d9072d1d43",
   "metadata": {},
   "source": [
    "#### 2.4 Monthly Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be925c2-5a1e-499a-9be1-f0060c8dc802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+\n",
      "|Symbol|              month|monthly_volatility|\n",
      "+------+-------------------+------------------+\n",
      "|  NVDA|2024-03-01 00:00:00|  3.19225511782661|\n",
      "|  AMZN|2024-08-01 00:00:00| 6.445405383445364|\n",
      "|  AVGO|2024-12-01 00:00:00|  31.6445725773839|\n",
      "|  TSLA|2024-11-01 00:00:00| 34.60325024954025|\n",
      "|   SPY|2024-03-01 00:00:00|5.3122021266211235|\n",
      "|  AAPL|2024-04-01 00:00:00|  2.75979884664453|\n",
      "|  MSFT|2024-10-01 00:00:00| 6.505105737121832|\n",
      "|   SPY|2024-04-01 00:00:00| 8.037746030590498|\n",
      "|  AAPL|2024-08-01 00:00:00| 6.894340138490561|\n",
      "| GOOGL|2024-01-01 00:00:00|5.3201708695985905|\n",
      "|   SPY|2024-08-01 00:00:00|15.359290788146952|\n",
      "|   SPY|2024-02-01 00:00:00| 5.617393502720848|\n",
      "|  AVGO|2024-03-01 00:00:00|5.4289384974893045|\n",
      "|  META|2024-02-01 00:00:00|20.360763034805082|\n",
      "|   SPY|2024-05-01 00:00:00| 8.381732485560372|\n",
      "| BRK-B|2024-09-01 00:00:00| 7.740633561813219|\n",
      "|  AVGO|2024-07-01 00:00:00|  9.31982569561325|\n",
      "|  AAPL|2024-03-01 00:00:00|2.8734643351689013|\n",
      "|  TSLA|2024-01-01 00:00:00|20.442824018402018|\n",
      "|  GOOG|2024-01-01 00:00:00| 5.323172024475695|\n",
      "+------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stocks\n",
    "spark.sql(\"\"\"\n",
    "   SELECT Symbol, DATE_TRUNC('month', Date) AS month, STDDEV(Close) AS monthly_volatility \n",
    "   FROM stocks \n",
    "   GROUP BY Symbol, month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b3bb736-5969-41af-b121-0be279f520e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------------------+\n",
      "|coin_name|              month|  monthly_volatility|\n",
      "+---------+-------------------+--------------------+\n",
      "|     DOGE|2024-12-01 00:00:00| 0.05146356701032425|\n",
      "|      DOT|2024-09-01 00:00:00|  0.2517486375449671|\n",
      "|      ETH|2024-11-01 00:00:00|   364.9937401275454|\n",
      "|      BTC|2024-03-01 00:00:00|   3109.738688745365|\n",
      "|      ADA|2024-01-01 00:00:00|0.037844254610782065|\n",
      "|      DOT|2024-07-01 00:00:00|  0.3036426374709631|\n",
      "|      TRX|2024-07-01 00:00:00|0.004066681153474227|\n",
      "|      ADA|2024-12-01 00:00:00|  0.1285970226814527|\n",
      "|      XLM|2024-10-01 00:00:00|0.002259648524964068|\n",
      "|      ADA|2024-09-01 00:00:00| 0.02518933206245201|\n",
      "|      BTC|2024-02-01 00:00:00|   5125.139363336347|\n",
      "|      SOL|2024-06-01 00:00:00|  13.106615748238415|\n",
      "|      TRX|2024-11-01 00:00:00|0.018150246206198057|\n",
      "|      DOT|2024-10-01 00:00:00| 0.13797729570125747|\n",
      "|      ETH|2024-02-01 00:00:00|  333.45818930924503|\n",
      "|      SOL|2024-04-01 00:00:00|   18.93278849188849|\n",
      "|      DOT|2024-04-01 00:00:00|  0.9076205246586306|\n",
      "|      TRX|2024-12-01 00:00:00| 0.04124533352752826|\n",
      "|      ETH|2024-10-01 00:00:00|   106.1508125600587|\n",
      "|     AVAX|2024-05-01 00:00:00|  2.3013531032715457|\n",
      "+---------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#crypto\n",
    "spark.sql(\"\"\"\n",
    "   SELECT coin_name, DATE_TRUNC('month', timestamp) AS month, STDDEV(close) AS monthly_volatility\n",
    "   FROM crypto\n",
    "   GROUP BY coin_name, month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5916b-8de2-4918-9c42-b0afd709eb5a",
   "metadata": {},
   "source": [
    "#### 2.5 Volume spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9944bb9-8839-44a9-b9ad-88bbca027f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "from pyspark.sql.functions import avg, col, round as round_\n",
    "from pyspark.sql.window import Window\n",
    "#stock\n",
    "window_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-7, -1)\n",
    "\n",
    "df_stocks = df_stocks.withColumn(\"avg_weekly_vol\", avg(\"Volume\").over(window_stock)) \\\n",
    "                     .withColumn(\"volume_spike\", col(\"Volume\") / col(\"avg_weekly_vol\"))\n",
    "\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "\n",
    "#crypto\n",
    "window_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\").rowsBetween(-7, -1)\n",
    "\n",
    "df_crypto = df_crypto.withColumn(\"avg_weekly_vol\", avg(\"volume\").over(window_crypto)) \\\n",
    "                     .withColumn(\"volume_spike\", col(\"volume\") / col(\"avg_weekly_vol\"))\n",
    "\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f74c2e2-198e-432c-89ca-1aeb2c035e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+------------+-----+\n",
      "|asset|               date|volume_spike| type|\n",
      "+-----+-------------------+------------+-----+\n",
      "| AAPL|2024-09-20 00:00:00|        6.37|Stock|\n",
      "| META|2024-02-02 00:00:00|        4.51|Stock|\n",
      "| META|2024-04-25 00:00:00|        4.39|Stock|\n",
      "| META|2024-12-20 00:00:00|        4.15|Stock|\n",
      "| AVGO|2024-12-13 00:00:00|        3.93|Stock|\n",
      "| GOOG|2024-06-21 00:00:00|        3.84|Stock|\n",
      "| TSLA|2024-10-24 00:00:00|        3.72|Stock|\n",
      "| AMZN|2024-08-02 00:00:00|         3.3|Stock|\n",
      "| AVGO|2024-05-31 00:00:00|        3.29|Stock|\n",
      "|BRK-B|2024-12-20 00:00:00|        3.18|Stock|\n",
      "+-----+-------------------+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#stocks\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol AS asset, Date AS date, ROUND(volume_spike, 2) AS volume_spike, 'Stock' AS type\n",
    "    FROM stocks\n",
    "    WHERE volume_spike IS NOT NULL\n",
    "    ORDER BY volume_spike DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd654d4d-2af6-4b8b-a2c9-7968f248d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+------------+------+\n",
      "|asset|               date|volume_spike|  type|\n",
      "+-----+-------------------+------------+------+\n",
      "|  ADA|2024-12-05 00:00:00|      123.31|Crypto|\n",
      "|  SOL|2024-12-05 00:00:00|       83.08|Crypto|\n",
      "|  TRX|2024-12-03 00:00:00|        64.1|Crypto|\n",
      "|  XRP|2024-12-05 00:00:00|       60.37|Crypto|\n",
      "|  XLM|2024-09-17 01:00:00|       27.11|Crypto|\n",
      "|  ETH|2024-12-03 00:00:00|       23.44|Crypto|\n",
      "|  ETH|2024-12-05 00:00:00|       15.05|Crypto|\n",
      "|  BTC|2024-11-25 00:00:00|       10.71|Crypto|\n",
      "| AVAX|2024-06-22 01:00:00|       10.41|Crypto|\n",
      "|  TRX|2024-12-07 00:00:00|        9.95|Crypto|\n",
      "+-----+-------------------+------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name AS asset, timestamp AS date, ROUND(volume_spike, 2) AS volume_spike, 'Crypto' AS type\n",
    "    FROM crypto\n",
    "    WHERE volume_spike IS NOT NULL\n",
    "    ORDER BY volume_spike DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc4ad1-6cdd-4987-bc14-0e048c50c689",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis Summary\n",
    "\n",
    "Our EDA dives into key activity and volatility metrics across both stock and crypto markets for 2024, offering a cross-asset perspective.\n",
    "\n",
    "#### Trading Volume\n",
    "- Among stocks, **NVDA**, **TSLA**, and **SPY** dominate in terms of total traded volume — aligning with their popularity and market visibility.\n",
    "- In crypto, **DOGE** surprisingly leads, followed by **XRP** and **ADA** — highlighting how community-driven or meme-based assets can overshadow even large-cap coins in trading activity.\n",
    "\n",
    "#### Daily Price Gap (High - Low)\n",
    "- For stocks, significant price gaps were observed in **META**, **TSLA**, and **MSFT**, indicating reactive price movement — possibly driven by news, earnings, or macro events.\n",
    "- For crypto, **SOLANA (SOL)** showed large price swings across multiple consecutive days, showing intense volatility and potential for high intraday gains or losses.\n",
    "\n",
    "#### Monthly Volatility\n",
    "- Stocks like **TSLA (Nov)** and **AVGO (Dec)** posted extreme standard deviations in closing prices, marking them as high-risk, high-opportunity assets during those windows.\n",
    "- Crypto volatility peaked with **ETH**, **BTC**, and **SOL**, particularly in November and December — potentially tied to market speculation or ecosystem events.\n",
    "\n",
    "#### Volume Spikes (Abnormal Activity)\n",
    "- For stocks, names like **AAPL**, **META**, and **GOOG** showed days with trading volumes 3x–6x above their 7-day average — ideal candidates for identifying news or investor sentiment shifts.\n",
    "- In crypto, **ADA**, **SOL**, and **TRX** showed enormous spikes (some >100x their weekly average) — usually a sign of breakout trading, whale moves, or news-triggered hype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2317b9-8ef4-46b3-ab10-ea795fc27220",
   "metadata": {},
   "source": [
    "### 3. Performance Metrics\n",
    "#### 3.1 Daily Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67e2c4f0-30a1-4212-90d7-02980a474dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lag, col, first, last, weekofyear\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Stocks: Daily Return\n",
    "window_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\")\n",
    "df_stocks = df_stocks.withColumn(\n",
    "    \"daily_return\",\n",
    "    (col(\"Close\") - lag(\"Close\").over(window_stock)) / lag(\"Close\").over(window_stock)\n",
    ")\n",
    "\n",
    "# Crypto: Daily Return\n",
    "window_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\")\n",
    "df_crypto = df_crypto.withColumn(\n",
    "    \"daily_return\",\n",
    "    (col(\"close\") - lag(\"close\").over(window_crypto)) / lag(\"close\").over(window_crypto)\n",
    ")\n",
    "\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab26f7de-c7b3-4aae-a587-1f7dfd255034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------+\n",
      "|Symbol|               Date|daily_return|\n",
      "+------+-------------------+------------+\n",
      "|  AAPL|2024-01-03 00:00:00|     -0.0075|\n",
      "|  AAPL|2024-01-04 00:00:00|     -0.0127|\n",
      "|  AAPL|2024-01-05 00:00:00|      -0.004|\n",
      "|  AAPL|2024-01-08 00:00:00|      0.0242|\n",
      "|  AAPL|2024-01-09 00:00:00|     -0.0023|\n",
      "|  AAPL|2024-01-10 00:00:00|      0.0057|\n",
      "|  AAPL|2024-01-11 00:00:00|     -0.0032|\n",
      "|  AAPL|2024-01-12 00:00:00|      0.0018|\n",
      "|  AAPL|2024-01-16 00:00:00|     -0.0123|\n",
      "|  AAPL|2024-01-17 00:00:00|     -0.0052|\n",
      "|  AAPL|2024-01-18 00:00:00|      0.0326|\n",
      "|  AAPL|2024-01-19 00:00:00|      0.0155|\n",
      "|  AAPL|2024-01-22 00:00:00|      0.0122|\n",
      "|  AAPL|2024-01-23 00:00:00|      0.0067|\n",
      "|  AAPL|2024-01-24 00:00:00|     -0.0035|\n",
      "|  AAPL|2024-01-25 00:00:00|     -0.0017|\n",
      "|  AAPL|2024-01-26 00:00:00|      -0.009|\n",
      "|  AAPL|2024-01-29 00:00:00|     -0.0036|\n",
      "|  AAPL|2024-01-30 00:00:00|     -0.0192|\n",
      "|  AAPL|2024-01-31 00:00:00|     -0.0194|\n",
      "+------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STOCKS\n",
    "spark.sql(\"\"\"\n",
    "   SELECT Symbol, Date, ROUND(daily_return, 4) AS daily_return \n",
    "   FROM stocks \n",
    "   WHERE daily_return IS NOT NULL \n",
    "   ORDER BY Symbol, Date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b53bd7-e1b3-4a4d-bee5-848d412d84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+\n",
      "|coin_name|               date|daily_return|\n",
      "+---------+-------------------+------------+\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-01 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|     -0.0293|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-02 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|     -0.0795|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "|      ADA|2024-01-03 00:00:00|         0.0|\n",
      "+---------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#CRYPTO\n",
    "spark.sql(\"\"\"\n",
    "   SELECT coin_name, timestamp AS date, ROUND(daily_return, 4) AS daily_return\n",
    "   FROM crypto\n",
    "   WHERE daily_return IS NOT NULL\n",
    "   ORDER BY coin_name, timestamp\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21bec3-1bb7-48fb-b218-d0b8fbfd0888",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### 3.2 Best and Worst Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb79811-46d1-4ffa-a3b9-bac95cc5e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks: Total Return (Open vs Close)\n",
    "df_stocks = df_stocks.withColumn(\n",
    "    \"total_return\",\n",
    "    (col(\"Close\") - col(\"Open\")) / col(\"Open\")\n",
    ")\n",
    "\n",
    "# Crypto: Total Return (Open vs Close)\n",
    "df_crypto = df_crypto.withColumn(\n",
    "    \"total_return\",\n",
    "    (col(\"close\") - col(\"open\")) / col(\"open\")\n",
    ")\n",
    "\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f4a7fa-5c59-44c4-a37d-81b04dbe08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|asset|return| type|\n",
      "+-----+------+-----+\n",
      "| AVGO|0.0962|Stock|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|asset|return|  type|\n",
      "+-----+------+------+\n",
      "|  TRX|0.9589|Crypto|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Stocks: Best Performer\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol AS asset, ROUND(total_return, 4) AS return, 'Stock' AS type\n",
    "    FROM stocks\n",
    "    ORDER BY return DESC\n",
    "    LIMIT 1\n",
    "\"\"\").show()\n",
    "# Crypto: Best Performer\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name AS asset, ROUND(total_return, 4) AS return, 'Crypto' AS type\n",
    "    FROM crypto\n",
    "    ORDER BY return DESC\n",
    "    LIMIT 1\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe6edaa-4d10-4415-8fb9-2367dc9eb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|asset|return| type|\n",
      "+-----+------+-----+\n",
      "| TSLA|-0.094|Stock|\n",
      "+-----+------+-----+\n",
      "\n",
      "+-----+-------+------+\n",
      "|asset| return|  type|\n",
      "+-----+-------+------+\n",
      "|  TRX|-0.2474|Crypto|\n",
      "+-----+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Stocks: Worst Performer\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol AS asset, ROUND(total_return, 4) AS return, 'Stock' AS type\n",
    "    FROM stocks\n",
    "    ORDER BY return ASC\n",
    "    LIMIT 1\n",
    "\"\"\").show()\n",
    "\n",
    "# Crypto: Worst Performer\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name AS asset, ROUND(total_return, 4) AS return, 'Crypto' AS type\n",
    "    FROM crypto\n",
    "    ORDER BY return ASC\n",
    "    LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14cff2-f9f0-44b8-a252-7bebd30f8a6c",
   "metadata": {},
   "source": [
    "#### 3.3 Custom Period Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "377b7c1c-ac0c-4bca-959b-0dddfcf17c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks: First & Last Close Return\n",
    "window_period_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\")\n",
    "df_stocks = df_stocks.withColumn(\"first_close\", first(\"Close\").over(window_period_stock)) \\\n",
    "                     .withColumn(\"last_close\", last(\"Close\").over(window_period_stock)) \\\n",
    "                     .withColumn(\"total_return_custom\", (col(\"last_close\") - col(\"first_close\")) / col(\"first_close\"))\n",
    "\n",
    "# Crypto: First & Last Close Return\n",
    "window_period_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\")\n",
    "df_crypto = df_crypto.withColumn(\"first_close\", first(\"close\").over(window_period_crypto)) \\\n",
    "                     .withColumn(\"last_close\", last(\"close\").over(window_period_crypto)) \\\n",
    "                     .withColumn(\"total_return_custom\", (col(\"last_close\") - col(\"first_close\")) / col(\"first_close\"))\n",
    "\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1145f4fb-1154-4948-84b8-867c1712facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|asset|return| type|\n",
      "+-----+------+-----+\n",
      "| NVDA|2.0915|Stock|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|asset|return|  type|\n",
      "+-----+------+------+\n",
      "| DOGE|4.0736|Crypto|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Top performers (Stock + Crypto)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol AS asset, ROUND(total_return_custom, 4) AS return, 'Stock' AS type\n",
    "    FROM stocks\n",
    "    GROUP BY Symbol, total_return_custom\n",
    "    ORDER BY return DESC\n",
    "    LIMIT 1\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name AS asset, ROUND(total_return_custom, 4) AS return, 'Crypto' AS type\n",
    "    FROM crypto\n",
    "    GROUP BY coin_name, total_return_custom\n",
    "    ORDER BY return DESC\n",
    "    LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61421a-0d7f-463c-8897-836604efaa42",
   "metadata": {},
   "source": [
    "#### 3.4 Weekly return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7deb8400-04f1-4478-815d-78128176ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks\n",
    "df_stocks = df_stocks.withColumn(\"week\", weekofyear(\"Date\"))\n",
    "# Crypto\n",
    "df_crypto = df_crypto.withColumn(\"week\", weekofyear(\"timestamp\"))\n",
    "\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b61e3675-df68-4a04-8aa9-ba213b96806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------+-----+\n",
      "|asset|week|weekly_return| type|\n",
      "+-----+----+-------------+-----+\n",
      "| AAPL|   1|      -0.0094|Stock|\n",
      "| AAPL|   2|       0.0052|Stock|\n",
      "| AAPL|   3|       0.0077|Stock|\n",
      "| AAPL|   4|       9.0E-4|Stock|\n",
      "| AAPL|   5|      -0.0069|Stock|\n",
      "| AAPL|   6|       0.0035|Stock|\n",
      "| AAPL|   7|       -0.007|Stock|\n",
      "| AAPL|   8|       3.0E-4|Stock|\n",
      "| AAPL|   9|      -0.0031|Stock|\n",
      "| AAPL|  10|        -0.01|Stock|\n",
      "| AAPL|  11|       0.0022|Stock|\n",
      "| AAPL|  12|      -2.0E-4|Stock|\n",
      "| AAPL|  13|      -0.0011|Stock|\n",
      "| AAPL|  14|      -0.0022|Stock|\n",
      "| AAPL|  15|       0.0083|Stock|\n",
      "| AAPL|  16|      -0.0134|Stock|\n",
      "| AAPL|  17|       0.0052|Stock|\n",
      "| AAPL|  18|       0.0165|Stock|\n",
      "| AAPL|  19|      -1.0E-4|Stock|\n",
      "| AAPL|  20|       0.0074|Stock|\n",
      "+-----+----+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------+------+\n",
      "|asset|week|weekly_return|  type|\n",
      "+-----+----+-------------+------+\n",
      "|  ADA|   1|      -0.0039|Crypto|\n",
      "|  ADA|   2|       0.0015|Crypto|\n",
      "|  ADA|   3|      -8.0E-4|Crypto|\n",
      "|  ADA|   4|      -5.0E-4|Crypto|\n",
      "|  ADA|   5|       2.0E-4|Crypto|\n",
      "|  ADA|   6|        0.002|Crypto|\n",
      "|  ADA|   7|       0.0028|Crypto|\n",
      "|  ADA|   8|      -9.0E-4|Crypto|\n",
      "|  ADA|   9|       0.0044|Crypto|\n",
      "|  ADA|  10|      -1.0E-4|Crypto|\n",
      "|  ADA|  11|      -9.0E-4|Crypto|\n",
      "|  ADA|  12|      -8.0E-4|Crypto|\n",
      "|  ADA|  13|       1.0E-4|Crypto|\n",
      "|  ADA|  14|      -0.0019|Crypto|\n",
      "|  ADA|  15|      -0.0043|Crypto|\n",
      "|  ADA|  16|       0.0014|Crypto|\n",
      "|  ADA|  17|      -0.0016|Crypto|\n",
      "|  ADA|  18|      -1.0E-4|Crypto|\n",
      "|  ADA|  19|      -9.0E-4|Crypto|\n",
      "|  ADA|  20|       0.0014|Crypto|\n",
      "+-----+----+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Stocks: Weekly return\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol AS asset, week, ROUND(AVG(daily_return), 4) AS weekly_return, 'Stock' AS type\n",
    "    FROM stocks\n",
    "    GROUP BY Symbol, week\n",
    "    ORDER BY Symbol, week\n",
    "\"\"\").show()\n",
    "\n",
    "# Crypto: Weekly return\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name AS asset, week, ROUND(AVG(daily_return), 4) AS weekly_return, 'Crypto' AS type\n",
    "    FROM crypto\n",
    "    GROUP BY coin_name, week\n",
    "    ORDER BY coin_name, week\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc8b25-61c0-4743-a7a6-6d733caac367",
   "metadata": {},
   "source": [
    "### Performance Metrics Summary\n",
    "\n",
    "This section captures how individual stock and crypto assets performed over time, using return-based metrics to assess both consistency and extremes.\n",
    "\n",
    "#### Daily Return\n",
    "- **Stocks** like **AAPL** showed expected day-to-day fluctuations, reflecting natural market cycles. Values range from small negative to moderate positive returns, highlighting both correction and growth phases.\n",
    "- **Crypto** assets (e.g. **ADA**) showed repeated zero returns, suggesting data granularity issues or periods of low activity — though some days reflect sharp price drops or gains, emphasizing crypto’s jumpy nature.\n",
    "\n",
    "#### Best & Worst Performing Assets\n",
    "- Over the open-to-close daily window:\n",
    "  - **Top stock performer:** **AVGO**, signaling strong intraday growth.\n",
    "  - **Top crypto performer:** **TRX**, showing potential for explosive short-term gains.\n",
    "  - **Worst stock performer:** **TSLA**, possibly tied to a bearish phase or correction.\n",
    "  - **Worst crypto performer:** Also **TRX**, reinforcing the volatility theme in crypto.\n",
    "- Crypto assets can swing from top to bottom across different periods — unlike stocks, which tend to be more stable.\n",
    "\n",
    "#### Custom Period Return (First to Last Close)\n",
    "- Over the full dataset timeline:\n",
    "  - **Top stock:** **NVDA**, with a return >2x — consistent with its strong 2024 rally.\n",
    "  - **Top crypto:** **DOGE**, boasting over 4x return — meme coins often outperform in bull cycles.\n",
    "- Stocks show solid growth; crypto shows outsized returns but with less predictability.\n",
    "\n",
    "#### Weekly Return\n",
    "- Weekly stock returns (e.g. **AAPL**) offer smoother insights than daily — still minor swings, but more readable trends.\n",
    "- Weekly crypto returns (e.g. **ADA**) range from mild to volatile, but average out better over time — suggesting improved stability when zoomed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ebbeb-737b-43cd-8692-650f16058a3c",
   "metadata": {},
   "source": [
    "### 4. Volatility & Risk\n",
    "### 4.1 Rolling 7-day volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f96f769-16ea-4adb-84c1-a5e5a7e0b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from pyspark.sql.functions import stddev, avg, col,year\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#Rolling 7-Day Volatility\n",
    "\n",
    "# Stock window\n",
    "rolling_window_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-6, 0)\n",
    "df_stocks = df_stocks.withColumn(\"7_day_volatility\", stddev(\"daily_return\").over(rolling_window_stock))\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "\n",
    "# Crypto window\n",
    "rolling_window_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\").rowsBetween(-6, 0)\n",
    "df_crypto = df_crypto.withColumn(\"7_day_volatility\", stddev(\"daily_return\").over(rolling_window_crypto))\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b85ed96d-eec1-42d8-847c-336845807293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+\n",
      "|Symbol|               Date|rolling_volatility|\n",
      "+------+-------------------+------------------+\n",
      "|  AAPL|2024-01-04 00:00:00|            0.0037|\n",
      "|  AAPL|2024-01-05 00:00:00|            0.0044|\n",
      "|  AAPL|2024-01-08 00:00:00|            0.0165|\n",
      "|  AAPL|2024-01-09 00:00:00|            0.0143|\n",
      "|  AAPL|2024-01-10 00:00:00|            0.0131|\n",
      "|  AAPL|2024-01-11 00:00:00|             0.012|\n",
      "|  AAPL|2024-01-12 00:00:00|            0.0115|\n",
      "|  AAPL|2024-01-16 00:00:00|            0.0115|\n",
      "|  AAPL|2024-01-17 00:00:00|            0.0116|\n",
      "|  AAPL|2024-01-18 00:00:00|            0.0144|\n",
      "|  AAPL|2024-01-19 00:00:00|             0.015|\n",
      "|  AAPL|2024-01-22 00:00:00|            0.0153|\n",
      "|  AAPL|2024-01-23 00:00:00|            0.0147|\n",
      "|  AAPL|2024-01-24 00:00:00|            0.0152|\n",
      "|  AAPL|2024-01-25 00:00:00|            0.0134|\n",
      "|  AAPL|2024-01-26 00:00:00|            0.0141|\n",
      "|  AAPL|2024-01-29 00:00:00|            0.0092|\n",
      "|  AAPL|2024-01-30 00:00:00|            0.0102|\n",
      "|  AAPL|2024-01-31 00:00:00|            0.0095|\n",
      "|  AAPL|2024-02-01 00:00:00|            0.0113|\n",
      "+------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query rolling volatility (Stocks)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol, Date, ROUND(7_day_volatility, 4) AS rolling_volatility\n",
    "    FROM stocks\n",
    "    WHERE 7_day_volatility IS NOT NULL\n",
    "    ORDER BY Symbol, Date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8172c1a9-da4c-4990-ad3b-1f69042ad8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------------+\n",
      "|coin_name|               date|rolling_volatility|\n",
      "+---------+-------------------+------------------+\n",
      "|      ADA|2024-01-01 00:00:00|               0.0|\n",
      "|      ADA|2024-01-01 00:00:00|               0.0|\n",
      "|      ADA|2024-01-01 00:00:00|               0.0|\n",
      "|      ADA|2024-01-01 00:00:00|               0.0|\n",
      "|      ADA|2024-01-01 00:00:00|               0.0|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-02 00:00:00|            0.0111|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-03 00:00:00|              0.03|\n",
      "|      ADA|2024-01-04 00:00:00|             0.009|\n",
      "+---------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query rolling volatility (Crypto)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name, timestamp AS date, ROUND(7_day_volatility, 4) AS rolling_volatility\n",
    "    FROM crypto\n",
    "    WHERE 7_day_volatility IS NOT NULL\n",
    "    ORDER BY coin_name, date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce60c6-716d-4784-a6c0-ca187a256418",
   "metadata": {},
   "source": [
    "#### 4.2 Sharpe Ratio Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ce8efd4-5bbf-47f8-9b31-0ad07aab73a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+------------+\n",
      "|Symbol|avg_ret|volatility|sharpe_ratio|\n",
      "+------+-------+----------+------------+\n",
      "|  TSLA| 0.0029|    0.0401|       -0.43|\n",
      "|  NVDA| 0.0047|    0.0331|       -0.46|\n",
      "|  AVGO| 0.0037|     0.034|       -0.48|\n",
      "|  META| 0.0024|     0.023|       -0.76|\n",
      "|  AMZN| 0.0017|    0.0177|       -1.03|\n",
      "| GOOGL| 0.0015|    0.0177|       -1.05|\n",
      "|  GOOG| 0.0015|    0.0175|       -1.06|\n",
      "|  AAPL| 0.0013|    0.0141|       -1.32|\n",
      "|  MSFT| 7.0E-4|    0.0126|       -1.54|\n",
      "| BRK-B| 9.0E-4|    0.0092|       -2.08|\n",
      "|   SPY|  0.001|    0.0079|        -2.4|\n",
      "+------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stocks\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Symbol,\n",
    "           ROUND(AVG(daily_return), 4) AS avg_ret,\n",
    "           ROUND(STDDEV(daily_return), 4) AS volatility,\n",
    "           ROUND((AVG(daily_return) - 0.02) / STDDEV(daily_return), 2) AS sharpe_ratio\n",
    "    FROM stocks\n",
    "    GROUP BY Symbol\n",
    "    ORDER BY sharpe_ratio DESC\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7c6bdbb-9db8-475f-89f2-b764637a3c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+------------+\n",
      "|coin_name|avg_ret|volatility|sharpe_ratio|\n",
      "+---------+-------+----------+------------+\n",
      "|      DOT| 3.0E-4|    0.0444|       -0.44|\n",
      "|      XLM| 0.0019|    0.0395|       -0.46|\n",
      "|      TRX| 4.0E-4|      0.02|       -0.98|\n",
      "|      ADA| 3.0E-4|    0.0167|       -1.18|\n",
      "|     DOGE| 3.0E-4|    0.0139|       -1.41|\n",
      "|     AVAX| 1.0E-4|    0.0132|       -1.51|\n",
      "|      XRP| 3.0E-4|    0.0111|       -1.78|\n",
      "|      SOL| 1.0E-4|    0.0104|        -1.9|\n",
      "|      ETH| 1.0E-4|    0.0088|       -2.27|\n",
      "|      BTC| 2.0E-4|     0.007|       -2.85|\n",
      "+---------+-------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name,\n",
    "           ROUND(AVG(daily_return), 4) AS avg_ret,\n",
    "           ROUND(STDDEV(daily_return), 4) AS volatility,\n",
    "           ROUND((AVG(daily_return) - 0.02) / STDDEV(daily_return), 2) AS sharpe_ratio\n",
    "    FROM crypto\n",
    "    GROUP BY coin_name\n",
    "    ORDER BY sharpe_ratio DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ed456-e280-426e-9e93-20ca076ee096",
   "metadata": {},
   "source": [
    "### Volatility & Risk Summary\n",
    "\n",
    "This section explores risk dynamics across stocks and crypto assets using **rolling volatility** and the **Sharpe ratio**, offering a cross-asset lens on return consistency and volatility exposure.\n",
    "\n",
    "#### Rolling 7-Day Volatility\n",
    "- Among stocks, **AAPL**, **META**, and **GOOG** exhibited rolling volatility ranging between **1%–1.6%**, showing relatively stable yet noticeable intraday fluctuations.\n",
    "- In crypto, **ADA** and **TRX** demonstrated much higher volatility bursts — crossing **3%+** on several occasions, reinforcing the market's **short-term unpredictability** and sensitivity to news or volume surges.\n",
    "- Rolling volatility effectively captures **near-term market choppiness**, helping identify **risk windows** and timing entry/exit points for trades.\n",
    "\n",
    "#### Sharpe Ratio (Risk-Adjusted Return)\n",
    "- Stock assets like **TSLA**, **AVGO**, and **NVDA** led with relatively higher (but still **negative**) Sharpe ratios, hinting at **suboptimal risk-adjusted returns** across the board in 2024.\n",
    "- Crypto Sharpe ratios were notably worse: **BTC**, **ETH**, and **DOGE** posted values as low as **-2.85**, **-2.27**, and **-1.41**, reflecting poor reward for the high volatility endured.\n",
    "- These figures suggest that while crypto may offer **explosive returns**, they rarely compensate for the corresponding **risk volatility**, especially when benchmarked to a 2% baseline return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01f3f8-ca30-4656-a09b-f08c6e97218e",
   "metadata": {},
   "source": [
    "### 5. Temporal Trends & Patterns\n",
    "#### 5.1 Quarterly average price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c6dd7c4-157e-4453-985e-32b44b6f657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------------------+\n",
      "|            quarter|Symbol|avg_quarterly_price|\n",
      "+-------------------+------+-------------------+\n",
      "|2024-01-01 00:00:00|  AAPL|             180.87|\n",
      "|2024-01-01 00:00:00|  AMZN|             166.93|\n",
      "|2024-01-01 00:00:00|  AVGO|             122.32|\n",
      "|2024-01-01 00:00:00| BRK-B|             393.34|\n",
      "|2024-01-01 00:00:00|  GOOG|             143.83|\n",
      "|2024-01-01 00:00:00| GOOGL|             142.54|\n",
      "|2024-01-01 00:00:00|  META|             444.61|\n",
      "|2024-01-01 00:00:00|  MSFT|              401.4|\n",
      "|2024-01-01 00:00:00|  NVDA|              72.46|\n",
      "|2024-01-01 00:00:00|   SPY|             491.81|\n",
      "|2024-01-01 00:00:00|  TSLA|             195.37|\n",
      "|2024-04-01 00:00:00|  AAPL|             185.75|\n",
      "|2024-04-01 00:00:00|  AMZN|              183.7|\n",
      "|2024-04-01 00:00:00|  AVGO|             138.91|\n",
      "|2024-04-01 00:00:00| BRK-B|             408.62|\n",
      "|2024-04-01 00:00:00|  GOOG|             169.54|\n",
      "|2024-04-01 00:00:00| GOOGL|             168.01|\n",
      "|2024-04-01 00:00:00|  META|             484.84|\n",
      "|2024-04-01 00:00:00|  MSFT|              419.5|\n",
      "|2024-04-01 00:00:00|  NVDA|             101.08|\n",
      "+-------------------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stocks\n",
    "spark.sql(\"\"\"\n",
    "    SELECT DATE_TRUNC('quarter', Date) AS quarter, Symbol, \n",
    "           ROUND(AVG(Close), 2) AS avg_quarterly_price\n",
    "    FROM stocks\n",
    "    GROUP BY quarter, Symbol\n",
    "    ORDER BY quarter, Symbol\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "846e5e51-8997-46bd-af56-f0e6d922cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------------------+\n",
      "|            quarter|coin_name|avg_quarterly_price|\n",
      "+-------------------+---------+-------------------+\n",
      "|2024-01-01 00:00:00|      ADA|                0.6|\n",
      "|2024-01-01 00:00:00|     AVAX|              41.42|\n",
      "|2024-01-01 00:00:00|      BTC|            53574.8|\n",
      "|2024-01-01 00:00:00|     DOGE|               0.11|\n",
      "|2024-01-01 00:00:00|      DOT|               8.21|\n",
      "|2024-01-01 00:00:00|      ETH|            2920.36|\n",
      "|2024-01-01 00:00:00|      SOL|             123.64|\n",
      "|2024-01-01 00:00:00|      TRX|               0.12|\n",
      "|2024-01-01 00:00:00|      XLM|               0.12|\n",
      "|2024-01-01 00:00:00|      XRP|               0.58|\n",
      "|2024-04-01 00:00:00|      ADA|               0.46|\n",
      "|2024-04-01 00:00:00|     AVAX|              35.47|\n",
      "|2024-04-01 00:00:00|      BTC|           65679.27|\n",
      "|2024-04-01 00:00:00|     DOGE|               0.15|\n",
      "|2024-04-01 00:00:00|      DOT|               6.98|\n",
      "|2024-04-01 00:00:00|      ETH|            3372.51|\n",
      "|2024-04-01 00:00:00|      SOL|             154.72|\n",
      "|2024-04-01 00:00:00|      TRX|               0.12|\n",
      "|2024-04-01 00:00:00|      XLM|               0.11|\n",
      "|2024-04-01 00:00:00|      XRP|               0.52|\n",
      "+-------------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT DATE_TRUNC('quarter', timestamp) AS quarter, coin_name,\n",
    "           ROUND(AVG(close), 2) AS avg_quarterly_price\n",
    "    FROM crypto\n",
    "    GROUP BY quarter, coin_name\n",
    "    ORDER BY quarter, coin_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7233f0-b08e-46c6-8f18-ccd83fad18f5",
   "metadata": {},
   "source": [
    "#### 5.2 Yearly performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28001035-ed64-4500-baf7-94061ea0d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|avg_yearly_return|\n",
      "+----+-----------------+\n",
      "|2024|             0.03|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stocks\n",
    "spark.sql(\"\"\"\n",
    "    SELECT YEAR(Date) AS year, \n",
    "           ROUND(AVG((Close - Open)/Open)*100, 2) AS avg_yearly_return\n",
    "    FROM stocks\n",
    "    GROUP BY year\n",
    "    ORDER BY year DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e33b89b5-4f85-477a-b491-ddc085b21c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|avg_yearly_return|\n",
      "+----+-----------------+\n",
      "|2024|             0.28|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT YEAR(timestamp) AS year, \n",
    "           ROUND(AVG((close - open)/open)*100, 2) AS avg_yearly_return\n",
    "    FROM crypto\n",
    "    GROUP BY year\n",
    "    ORDER BY year DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6468c-ad39-42b2-9e3e-42cd48c40dab",
   "metadata": {},
   "source": [
    "#### 5.3 Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0257d6c-2b43-4fe3-8747-e421f1f95a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks\n",
    "window_50_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-49, 0)\n",
    "window_200_stock = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-199, 0)\n",
    "\n",
    "df_stocks = df_stocks.withColumn(\"SMA_50\", avg(\"Close\").over(window_50_stock)) \\\n",
    "                     .withColumn(\"SMA_200\", avg(\"Close\").over(window_200_stock))\n",
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "\n",
    "# Crypto\n",
    "window_50_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\").rowsBetween(-49, 0)\n",
    "window_200_crypto = Window.partitionBy(\"coin_name\").orderBy(\"timestamp\").rowsBetween(-199, 0)\n",
    "\n",
    "df_crypto = df_crypto.withColumn(\"SMA_50\", avg(\"close\").over(window_50_crypto)) \\\n",
    "                     .withColumn(\"SMA_200\", avg(\"close\").over(window_200_crypto))\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddbc6db3-ad05-4868-8ac2-e6bb868d9399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------+-------+\n",
      "|Symbol|               Date|SMA_50|SMA_200|\n",
      "+------+-------------------+------+-------+\n",
      "|  AAPL|2024-01-02 00:00:00|184.53| 184.53|\n",
      "|  AAPL|2024-01-03 00:00:00|183.84| 183.84|\n",
      "|  AAPL|2024-01-04 00:00:00|182.84| 182.84|\n",
      "|  AAPL|2024-01-05 00:00:00|182.15| 182.15|\n",
      "|  AAPL|2024-01-08 00:00:00|182.61| 182.61|\n",
      "|  AAPL|2024-01-09 00:00:00|182.85| 182.85|\n",
      "|  AAPL|2024-01-10 00:00:00|183.17| 183.17|\n",
      "|  AAPL|2024-01-11 00:00:00|183.33| 183.33|\n",
      "|  AAPL|2024-01-12 00:00:00| 183.5|  183.5|\n",
      "|  AAPL|2024-01-16 00:00:00| 183.4|  183.4|\n",
      "|  AAPL|2024-01-17 00:00:00|183.24| 183.24|\n",
      "|  AAPL|2024-01-18 00:00:00|183.59| 183.59|\n",
      "|  AAPL|2024-01-19 00:00:00|184.12| 184.12|\n",
      "|  AAPL|2024-01-22 00:00:00|184.73| 184.73|\n",
      "|  AAPL|2024-01-23 00:00:00|185.35| 185.35|\n",
      "|  AAPL|2024-01-24 00:00:00|185.85| 185.85|\n",
      "|  AAPL|2024-01-25 00:00:00|186.27| 186.27|\n",
      "|  AAPL|2024-01-26 00:00:00|186.55| 186.55|\n",
      "|  AAPL|2024-01-29 00:00:00|186.76| 186.76|\n",
      "|  AAPL|2024-01-30 00:00:00|186.77| 186.77|\n",
      "+------+-------------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stocks\n",
    "spark.sql(\"\"\"\n",
    "   SELECT Symbol, Date, ROUND(SMA_50, 2) AS SMA_50, ROUND(SMA_200, 2) AS SMA_200 \n",
    "   FROM stocks \n",
    "   WHERE SMA_50 IS NOT NULL AND SMA_200 IS NOT NULL \n",
    "   ORDER BY Symbol, Date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71b5415d-a441-48f1-9e87-961268a99f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------+-------+\n",
      "|coin_name|               date|SMA_50|SMA_200|\n",
      "+---------+-------------------+------+-------+\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-01 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.62|   0.62|\n",
      "|      ADA|2024-01-02 00:00:00|  0.61|   0.61|\n",
      "|      ADA|2024-01-03 00:00:00|  0.61|   0.61|\n",
      "|      ADA|2024-01-03 00:00:00|  0.61|   0.61|\n",
      "|      ADA|2024-01-03 00:00:00|   0.6|    0.6|\n",
      "|      ADA|2024-01-03 00:00:00|   0.6|    0.6|\n",
      "|      ADA|2024-01-03 00:00:00|   0.6|    0.6|\n",
      "|      ADA|2024-01-03 00:00:00|   0.6|    0.6|\n",
      "+---------+-------------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#crypto\n",
    "spark.sql(\"\"\"\n",
    "    SELECT coin_name, timestamp AS date, \n",
    "           ROUND(SMA_50, 2) AS SMA_50, ROUND(SMA_200, 2) AS SMA_200\n",
    "    FROM crypto\n",
    "    WHERE SMA_50 IS NOT NULL AND SMA_200 IS NOT NULL\n",
    "    ORDER BY coin_name, date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a634c72-3ea9-4c11-bb9f-b0836f0ea2a7",
   "metadata": {},
   "source": [
    "### Temporal Trends & Patterns Summary\n",
    "\n",
    "This section examines how stock and crypto assets evolve across different time horizons — quarterly, yearly, and with moving averages — to highlight seasonality, momentum, and macro-level patterns.\n",
    "\n",
    "#### Quarterly Average Price\n",
    "- In stocks, **META**, **SPY**, and **MSFT** exhibited consistently high quarterly averages — reflecting strength and stability across quarters.\n",
    "- For crypto, top-value assets like **BTC** and **ETH** posted the highest quarterly averages (e.g., **BTC > $65k in Q2**), while **ADA**, **XLM**, and **TRX** showed lower averages but potential for sharper relative gains due to their price sensitivity.\n",
    "\n",
    "#### Yearly Performance (2024)\n",
    "- **Crypto** outperformed stocks in 2024:  \n",
    "  - Stocks returned an average of **+0.03%**, indicating a flat year possibly due to broader market uncertainty.\n",
    "  - Cryptos surged with **+0.28%** on average — driven by recovery sentiment and speculative inflows.\n",
    "- This stark contrast underscores how market cycles can affect asset classes differently.\n",
    "\n",
    "#### Moving Averages (SMA 50 vs. SMA 200)\n",
    "- For stocks like **AAPL**, the **50-day SMA remained below the 200-day SMA** for extended periods — signaling caution or bearish trend continuation.\n",
    "- In crypto, moving averages for **ADA**, **XRP**, and **DOGE** were often flat or closely aligned, indicating low trend momentum or range-bound movement during certain periods.\n",
    "- These crossovers (or lack thereof) help flag potential trend reversals or confirm trend continuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c070a4-b320-4b95-92f1-6558e0f47cfe",
   "metadata": {},
   "source": [
    "### 6. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9374b865-fcae-45b1-b32d-08efb7af8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sentiment label\n",
    "from pyspark.sql.functions import when\n",
    "df_posts = df_posts.withColumn(\"sentiment_label\",\n",
    "    when(col(\"polarity\") > 0.1, \"Positive\")\n",
    "    .when(col(\"polarity\") < -0.1, \"Negative\")\n",
    "    .otherwise(\"Neutral\"))\n",
    "df_posts.createOrReplaceTempView(\"posts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61e59c6b-4a86-4d06-834a-426c153d5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rolling sentiment\n",
    "rolling = Window.orderBy(\"timestamp\").rowsBetween(-6, 0)\n",
    "df_posts = df_posts.withColumn(\"rolling_sentiment\", avg(\"polarity\").over(rolling))\n",
    "df_posts.createOrReplaceTempView(\"posts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d114a54-a14f-493b-b0e3-ba782cf4631f",
   "metadata": {},
   "source": [
    "#### 6.1 Avg daily sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f151a49b-70aa-49ad-87e7-69aabd87800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          timestamp|avg_daily_polarity|\n",
      "+-------------------+------------------+\n",
      "|               NULL|               0.0|\n",
      "|2010-10-19 00:00:00|            0.1292|\n",
      "|2010-10-21 00:00:00|               0.0|\n",
      "|2010-10-22 00:00:00|            0.2313|\n",
      "|2010-10-25 00:00:00|               0.0|\n",
      "|2010-10-26 00:00:00|            0.3143|\n",
      "|2010-10-27 00:00:00|              0.23|\n",
      "|2010-10-31 00:00:00|             0.119|\n",
      "|2013-04-02 00:00:00|            0.3575|\n",
      "|2013-04-04 00:00:00|            0.0406|\n",
      "|2013-04-18 00:00:00|               0.1|\n",
      "|2020-05-03 00:00:00|             0.188|\n",
      "|2020-05-13 00:00:00|            0.2069|\n",
      "|2020-06-12 00:00:00|            0.1014|\n",
      "|2020-07-08 00:00:00|               0.8|\n",
      "|2020-09-15 00:00:00|            0.1606|\n",
      "|2020-09-22 00:00:00|            -0.082|\n",
      "|2020-09-23 00:00:00|              0.34|\n",
      "|2020-12-03 00:00:00|             0.112|\n",
      "|2022-12-22 00:00:00|           -0.0712|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT timestamp, ROUND(AVG(polarity), 4) AS avg_daily_polarity \n",
    "   FROM posts \n",
    "   GROUP BY timestamp \n",
    "   ORDER BY timestamp\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3be49-c16f-460d-8993-c67000677d1c",
   "metadata": {},
   "source": [
    "#### 6.2 Sentiment by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ad737b4-efa0-4446-a129-b4b15dc0de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+\n",
      "|          timestamp|subsection|       avg_polarity|\n",
      "+-------------------+----------+-------------------+\n",
      "|2024-01-02 00:00:00|       BTC|     0.169642572845|\n",
      "|2024-12-24 00:00:00|       BTC|      0.07767320245|\n",
      "|2024-10-28 00:00:00|      DOGE|0.05538033395714286|\n",
      "|2024-10-29 00:00:00|      DOGE|0.17081651805384615|\n",
      "|2024-11-06 00:00:00|       BTC|       0.1938449306|\n",
      "|2024-11-08 00:00:00|       BTC|0.11535687230000002|\n",
      "|2024-11-18 00:00:00|       XRP|       0.0732195037|\n",
      "|2024-07-23 00:00:00|       ETH|       0.0758122896|\n",
      "|2024-02-08 00:00:00|       BTC|     0.182236925225|\n",
      "|2020-12-03 00:00:00|       SOL|              0.112|\n",
      "|2024-06-04 00:00:00|       XRP|0.14836647725000002|\n",
      "|2010-10-19 00:00:00|       BTC|0.12916666666666668|\n",
      "|2024-01-03 00:00:00|       BTC| 0.1788957548111111|\n",
      "|2024-12-05 00:00:00|       TRX|0.09723930480000001|\n",
      "|2024-10-09 00:00:00|       BTC|      0.19213541665|\n",
      "|2024-03-20 00:00:00|       BTC|0.13948335129999997|\n",
      "|2024-06-09 00:00:00|       ETH|      0.08296693444|\n",
      "|2024-04-27 00:00:00|       BTC|     0.141957316675|\n",
      "|2024-02-01 00:00:00|       BTC|      -0.0277777778|\n",
      "|2024-06-11 00:00:00|       ETH|                0.2|\n",
      "+-------------------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT timestamp, subsection, AVG(polarity) AS avg_polarity \n",
    "   FROM posts \n",
    "   GROUP BY timestamp, subsection\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13bc3b-7d5f-4010-aaba-2c4111a9f30e",
   "metadata": {},
   "source": [
    "#### 6.3 Positive & Negative posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5543ad66-0a33-43a5-b48d-3df913583beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------+\n",
      "|          timestamp|        cleaned_post|polarity|\n",
      "+-------------------+--------------------+--------+\n",
      "|2024-07-14 00:00:00|OnlyFans An excel...|     1.0|\n",
      "|2024-03-13 00:00:00|I agree to the ot...|     1.0|\n",
      "|2020-07-08 00:00:00|Hey guys $SOL is ...|     0.8|\n",
      "|2024-06-22 00:00:00|Can Bitcoin be a ...|     0.7|\n",
      "|2024-01-02 00:00:00|I dont know that ...|   0.625|\n",
      "+-------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT timestamp, cleaned_post, polarity \n",
    "   FROM posts \n",
    "   ORDER BY polarity \n",
    "   DESC LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "399705e6-a4e4-4164-8144-58b11e773b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+\n",
      "|          timestamp|        cleaned_post|     polarity|\n",
      "+-------------------+--------------------+-------------+\n",
      "|2024-07-28 00:00:00|I agree, currency...|         -0.8|\n",
      "|2024-07-28 00:00:00|I agree, currency...|       -0.345|\n",
      "|2024-03-11 00:00:00|Kucoin o Coinbase...|-0.3333333333|\n",
      "|2024-03-15 00:00:00|What wallet are y...|-0.3083333333|\n",
      "|2010-10-19 00:00:00|-10BTC for forced...|         -0.3|\n",
      "+-------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT timestamp, cleaned_post, polarity \n",
    "   FROM posts \n",
    "   ORDER BY polarity \n",
    "   ASC LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cfba6-3199-40c5-8fd6-a6e438ad45ba",
   "metadata": {},
   "source": [
    "#### 6.4 Sentiment label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2595b88-7734-44ff-ad18-d43cf1e8b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|sentiment_label|count|\n",
      "+---------------+-----+\n",
      "|       Positive|  853|\n",
      "|        Neutral|  635|\n",
      "|       Negative|   38|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT sentiment_label, COUNT(*) AS count\n",
    "   FROM posts \n",
    "   GROUP BY sentiment_label\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3875b-9e66-47bf-8ec8-fb96ced1f682",
   "metadata": {},
   "source": [
    "#### 6.5  Sentiment volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c13113b-32c8-4183-8f4b-393877784d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+\n",
      "|          timestamp|       avg_polarity|post_count|\n",
      "+-------------------+-------------------+----------+\n",
      "|               NULL|                0.0|        94|\n",
      "|2010-10-19 00:00:00|0.12916666666666668|         3|\n",
      "|2010-10-21 00:00:00|                0.0|         1|\n",
      "|2010-10-22 00:00:00|            0.23125|         5|\n",
      "|2010-10-25 00:00:00|                0.0|         2|\n",
      "|2010-10-26 00:00:00|       0.3142857143|         1|\n",
      "|2010-10-27 00:00:00| 0.2299886621142857|         7|\n",
      "|2010-10-31 00:00:00|        0.119047619|         1|\n",
      "|2013-04-02 00:00:00|        0.357521645|         2|\n",
      "|2013-04-04 00:00:00|           0.040625|         1|\n",
      "|2013-04-18 00:00:00|                0.1|         1|\n",
      "|2020-05-03 00:00:00|0.18797348484999998|         6|\n",
      "|2020-05-13 00:00:00|0.20685714285999998|         5|\n",
      "|2020-06-12 00:00:00|      0.10139668365|         2|\n",
      "|2020-07-08 00:00:00|                0.8|         1|\n",
      "|2020-09-15 00:00:00|     0.160602678575|         4|\n",
      "|2020-09-22 00:00:00|             -0.082|         1|\n",
      "|2020-09-23 00:00:00|               0.34|         1|\n",
      "|2020-12-03 00:00:00|              0.112|         2|\n",
      "|2022-12-22 00:00:00|      -0.0711538462|         1|\n",
      "+-------------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   SELECT timestamp, AVG(polarity) AS avg_polarity, COUNT(post) AS post_count \n",
    "   FROM posts \n",
    "   GROUP BY timestamp \n",
    "   ORDER BY timestamp\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83bee1-735a-48a4-942a-3c181384111d",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Summary\n",
    "\n",
    "This section explores the tone and emotion behind user-generated content, uncovering how sentiment trends correlate with asset discussions over time.\n",
    "\n",
    "####  Avg Daily Sentiment\n",
    "- Overall average polarity fluctuated across the timeline, with noticeable **positive spikes** in 2013 and **negative dips** around late 2020 and early 2022.\n",
    "- Daily sentiment varies, indicating **market mood swings** likely tied to major events or price movements.\n",
    "\n",
    "#### Sentiment by Topic\n",
    "- **BTC** consistently appeared across timestamps with mild to moderately positive sentiment (e.g., Jan 2 and Nov 6).\n",
    "- Posts tagged under **DOGE**, **SOL**, and **TRX** also show mostly positive polarity, reaffirming strong community backing.\n",
    "- **ETH** appeared slightly neutral to positive, while **XRP** sentiment fluctuated.\n",
    "\n",
    "#### Top Positive & Negative Posts\n",
    "- The **most positive posts** expressed enthusiasm and optimism toward specific coins like $SOL and BTC adoption.\n",
    "- The **most negative posts** reflected strong skepticism or frustrations — often hinting at scams or exchange issues (e.g., Kucoin, forced withdrawal mentions).\n",
    "\n",
    "#### Sentiment Label Distribution\n",
    "- Most posts were **Positive (853)** or **Neutral (635)** — indicating a predominantly bullish or balanced tone in discussions.\n",
    "- Very few posts were **Negative (38)**, suggesting either a generally optimistic community or low representation of contrarian opinions.\n",
    "\n",
    "#### Sentiment Volume\n",
    "- Post volume was **heaviest during neutral sentiment days**, though high positivity also aligned with days of elevated activity.\n",
    "- Days like **2020-07-08** and **2020-05-13** saw extremely high polarity (+0.8, +0.26) paired with spikes in post count — likely around breakout discussions or news hype.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f610f2f-7716-4c3c-b00a-646950d73472",
   "metadata": {},
   "source": [
    "### 7. Merging All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34d5ac67-7c5e-453e-af9e-084887b4f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "# Aggregate stock data\n",
    "stocks_prepped = df_stocks.groupBy(\"Date\").agg(\n",
    "    avg(\"Open\").alias(\"s_open\"),\n",
    "    avg(\"Close\").alias(\"s_close\")\n",
    ").withColumnRenamed(\"Date\", \"DATE\")\n",
    "\n",
    "# Aggregate crypto data\n",
    "crypto_prepped = df_crypto.groupBy(\"timestamp\").agg(\n",
    "    avg(\"open\").alias(\"c_open\"),\n",
    "    avg(\"close\").alias(\"c_close\")\n",
    ").withColumnRenamed(\"timestamp\", \"DATE\")\n",
    "\n",
    "# Aggregate sentiment data\n",
    "sentiment_prepped = df_posts.groupBy(\"timestamp\").agg(\n",
    "    avg(\"polarity\").alias(\"sentiment\")\n",
    ").withColumnRenamed(\"timestamp\", \"DATE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19b8d18a-d2f4-4234-8648-7913fafd8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all 3 on DATE\n",
    "transformed_data = stocks_prepped \\\n",
    "    .join(crypto_prepped, on=\"DATE\", how=\"inner\") \\\n",
    "    .join(sentiment_prepped, on=\"DATE\", how=\"inner\")\n",
    "\n",
    "transformed_data.createOrReplaceTempView(\"transformed_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d9278-38ea-4a8b-a7cf-8ba116492f97",
   "metadata": {},
   "source": [
    "### 8. Combined Analysis\n",
    "#### 8.1 Price Comparison Between Stocks & Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c79bab47-cd7d-44c4-84eb-8b9157a9dee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+-----------------+\n",
      "|               DATE|stock_pct_change|crypto_pct_change|\n",
      "+-------------------+----------------+-----------------+\n",
      "|2024-01-02 00:00:00|           -0.32|              1.7|\n",
      "|2024-01-03 00:00:00|           -0.03|            -4.77|\n",
      "|2024-01-24 00:00:00|             0.0|             0.44|\n",
      "|2024-01-25 00:00:00|           -0.14|            -0.37|\n",
      "|2024-01-26 00:00:00|            0.03|             4.57|\n",
      "|2024-01-31 00:00:00|           -1.08|            -1.04|\n",
      "|2024-02-01 00:00:00|            0.63|             1.22|\n",
      "|2024-02-08 00:00:00|            0.09|             2.13|\n",
      "|2024-02-09 00:00:00|            0.72|             4.09|\n",
      "|2024-02-13 00:00:00|            0.21|            -0.45|\n",
      "|2024-02-14 00:00:00|            0.56|             4.28|\n",
      "|2024-02-26 00:00:00|            -0.9|             5.24|\n",
      "|2024-02-27 00:00:00|             0.1|             4.53|\n",
      "|2024-02-28 00:00:00|            0.03|             9.27|\n",
      "|2024-03-05 00:00:00|           -1.03|            -6.45|\n",
      "|2024-03-06 00:00:00|           -0.55|             3.83|\n",
      "|2024-03-07 00:00:00|            0.84|             1.27|\n",
      "|2024-03-11 00:00:00|           -0.23|             4.48|\n",
      "|2024-03-12 00:00:00|             0.8|            -0.91|\n",
      "|2024-03-13 00:00:00|           -0.24|             2.27|\n",
      "+-------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Daily Change Percentage (Stocks vs Crypto)\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE,\n",
    "  ROUND(((s_close - s_open)/s_open)*100, 2) AS stock_pct_change,\n",
    "  ROUND(((c_close - c_open)/c_open)*100, 2) AS crypto_pct_change\n",
    "FROM transformed_data\n",
    "ORDER BY DATE\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a33fcb-655c-48a1-99e0-0545961ae975",
   "metadata": {},
   "source": [
    "#### 8.2 Sentiment vs Daily Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46b4b52e-3d7c-461a-8c0f-14bcab85a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+-----------------+-------------+\n",
      "|               DATE|stock_pct_change|crypto_pct_change|avg_sentiment|\n",
      "+-------------------+----------------+-----------------+-------------+\n",
      "|2024-01-02 00:00:00|           -0.32|              1.7|         0.17|\n",
      "|2024-01-03 00:00:00|           -0.03|            -4.77|        0.179|\n",
      "|2024-01-24 00:00:00|             0.0|             0.44|        0.125|\n",
      "|2024-01-25 00:00:00|           -0.14|            -0.37|        0.204|\n",
      "|2024-01-26 00:00:00|            0.03|             4.57|        0.064|\n",
      "|2024-01-31 00:00:00|           -1.08|            -1.04|        0.097|\n",
      "|2024-02-01 00:00:00|            0.63|             1.22|       -0.028|\n",
      "|2024-02-08 00:00:00|            0.09|             2.13|        0.182|\n",
      "|2024-02-09 00:00:00|            0.72|             4.09|        0.235|\n",
      "|2024-02-13 00:00:00|            0.21|            -0.45|        0.174|\n",
      "|2024-02-14 00:00:00|            0.56|             4.28|        0.169|\n",
      "|2024-02-26 00:00:00|            -0.9|             5.24|       -0.121|\n",
      "|2024-02-27 00:00:00|             0.1|             4.53|        0.062|\n",
      "|2024-02-28 00:00:00|            0.03|             9.27|        0.148|\n",
      "|2024-03-05 00:00:00|           -1.03|            -6.45|        0.019|\n",
      "|2024-03-06 00:00:00|           -0.55|             3.83|        0.081|\n",
      "|2024-03-07 00:00:00|            0.84|             1.27|        0.159|\n",
      "|2024-03-11 00:00:00|           -0.23|             4.48|        0.128|\n",
      "|2024-03-12 00:00:00|             0.8|            -0.91|        0.233|\n",
      "|2024-03-13 00:00:00|           -0.24|             2.27|        0.323|\n",
      "+-------------------+----------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE,\n",
    "  ROUND(((s_close - s_open)/s_open)*100, 2) AS stock_pct_change,\n",
    "  ROUND(((c_close - c_open)/c_open)*100, 2) AS crypto_pct_change,\n",
    "  ROUND(sentiment, 3) AS avg_sentiment\n",
    "FROM transformed_data\n",
    "ORDER BY DATE\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922966f-f3a5-416c-b0de-6dc1fa21648e",
   "metadata": {},
   "source": [
    "#### 8.3 Days When Sentiment Was High but Prices Dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a95c6220-2a39-44e1-b571-a2e13e03684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------------+-----------------+\n",
      "|               DATE|sentiment|stock_pct_change|crypto_pct_change|\n",
      "+-------------------+---------+----------------+-----------------+\n",
      "|2024-03-13 00:00:00|    0.323|           -0.24|             2.27|\n",
      "+-------------------+---------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE,\n",
    "  ROUND(sentiment, 3) AS sentiment,\n",
    "  ROUND(((s_close - s_open)/s_open)*100, 2) AS stock_pct_change,\n",
    "  ROUND(((c_close - c_open)/c_open)*100, 2) AS crypto_pct_change\n",
    "FROM transformed_data\n",
    "WHERE sentiment > 0.3 \n",
    "  AND (((s_close - s_open)/s_open) < 0 OR ((c_close - c_open)/c_open) < 0)\n",
    "ORDER BY DATE\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c4c1a-557d-44b9-b297-eb3a477b0450",
   "metadata": {},
   "source": [
    "#### 8.4 Days When Sentiment Was Low but Prices Rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32ca6581-b798-4f0a-bec7-42c2488d9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------------+-----------------+\n",
      "|               DATE|sentiment|stock_pct_change|crypto_pct_change|\n",
      "+-------------------+---------+----------------+-----------------+\n",
      "|2024-02-01 00:00:00|   -0.028|            0.63|             1.22|\n",
      "|2024-02-26 00:00:00|   -0.121|            -0.9|             5.24|\n",
      "|2024-12-16 00:00:00|    0.025|            1.22|             1.62|\n",
      "+-------------------+---------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    DATE,\n",
    "    ROUND(sentiment, 3) AS sentiment,\n",
    "    ROUND(((s_close - s_open)/s_open)*100, 2) AS stock_pct_change,\n",
    "    ROUND(((c_close - c_open)/c_open)*100, 2) AS crypto_pct_change\n",
    "FROM transformed_data\n",
    "WHERE sentiment < 0.05\n",
    "  AND (((s_close - s_open)/s_open) > 0 OR ((c_close - c_open)/c_open) > 0)\n",
    "ORDER BY DATE\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158a43b-967d-4b0d-a87b-01406b027044",
   "metadata": {},
   "source": [
    "#### 8.5 Weekly Avg Sentiment and Market Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92f139aa-2892-4d9f-a3ff-dff53ca1eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+-----------------+\n",
      "|week_num|avg_weekly_sentiment|avg_stock_return|avg_crypto_return|\n",
      "+--------+--------------------+----------------+-----------------+\n",
      "|       1|                0.15|           -0.07|            -1.34|\n",
      "|       4|               0.131|           -0.04|             1.55|\n",
      "|       5|               0.035|           -0.23|             0.09|\n",
      "|       6|               0.208|            0.41|             3.11|\n",
      "|       7|               0.171|            0.39|             1.92|\n",
      "|       9|               0.029|           -0.26|             6.35|\n",
      "|      10|               0.087|           -0.25|            -0.45|\n",
      "|      11|               0.158|           -0.06|             0.16|\n",
      "|      12|                 0.1|            0.36|            -1.26|\n",
      "|      13|               0.124|           -0.24|             0.54|\n",
      "|      44|               0.124|           -0.66|             1.28|\n",
      "|      45|               0.136|            0.96|             3.23|\n",
      "|      46|               0.107|           -0.81|             0.34|\n",
      "|      47|               0.073|            0.12|             0.86|\n",
      "|      49|                0.17|            0.63|             1.08|\n",
      "|      50|               0.113|            0.17|             1.37|\n",
      "|      51|               0.025|            1.22|             1.62|\n",
      "|      52|               0.089|            1.05|             1.93|\n",
      "+--------+--------------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  WEEKOFYEAR(DATE) AS week_num,\n",
    "  ROUND(AVG(sentiment), 3) AS avg_weekly_sentiment,\n",
    "  ROUND(AVG((s_close - s_open)/s_open)*100, 2) AS avg_stock_return,\n",
    "  ROUND(AVG((c_close - c_open)/c_open)*100, 2) AS avg_crypto_return\n",
    "FROM transformed_data\n",
    "GROUP BY WEEKOFYEAR(DATE)\n",
    "ORDER BY week_num\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825ed1c-208c-427b-92c2-36fe222b4c63",
   "metadata": {},
   "source": [
    "#### 8.6 Lagged Sentiment vs Future Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "126b5e13-a707-4597-bcf6-2eb622e1c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 17:26:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:26:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------------+----------------------+\n",
      "|               DATE|sentiment|next_day_stock_return|next_day_crypto_return|\n",
      "+-------------------+---------+---------------------+----------------------+\n",
      "|2024-01-02 00:00:00|     0.17|                  0.0|                  -5.0|\n",
      "|2024-01-03 00:00:00|    0.179|                  0.0|                   0.0|\n",
      "|2024-01-24 00:00:00|    0.125|                  0.0|                   0.0|\n",
      "|2024-01-25 00:00:00|    0.204|                  0.0|                   5.0|\n",
      "|2024-01-26 00:00:00|    0.064|                 -1.0|                  -1.0|\n",
      "|2024-01-31 00:00:00|    0.097|                  1.0|                   1.0|\n",
      "|2024-02-01 00:00:00|   -0.028|                  0.0|                   2.0|\n",
      "|2024-02-08 00:00:00|    0.182|                  1.0|                   4.0|\n",
      "|2024-02-09 00:00:00|    0.235|                  0.0|                   0.0|\n",
      "|2024-02-13 00:00:00|    0.174|                  1.0|                   4.0|\n",
      "|2024-02-14 00:00:00|    0.169|                 -1.0|                   5.0|\n",
      "|2024-02-26 00:00:00|   -0.121|                  0.0|                   5.0|\n",
      "|2024-02-27 00:00:00|    0.062|                  0.0|                   9.0|\n",
      "|2024-02-28 00:00:00|    0.148|                 -1.0|                  -6.0|\n",
      "|2024-03-05 00:00:00|    0.019|                 -1.0|                   4.0|\n",
      "|2024-03-06 00:00:00|    0.081|                  1.0|                   1.0|\n",
      "|2024-03-07 00:00:00|    0.159|                  0.0|                   4.0|\n",
      "|2024-03-11 00:00:00|    0.128|                  1.0|                  -1.0|\n",
      "|2024-03-12 00:00:00|    0.233|                  0.0|                   2.0|\n",
      "|2024-03-13 00:00:00|    0.323|                  0.0|                  -2.0|\n",
      "+-------------------+---------+---------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE,\n",
    "  ROUND(sentiment, 3) AS sentiment,\n",
    "  LEAD(ROUND(((s_close - s_open)/s_open)*100), 1) OVER (ORDER BY DATE) AS next_day_stock_return,\n",
    "  LEAD(ROUND(((c_close - c_open)/c_open)*100), 1) OVER (ORDER BY DATE) AS next_day_crypto_return\n",
    "FROM transformed_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bb087-eac4-486d-a09a-d6b247d1de79",
   "metadata": {},
   "source": [
    "#### 8.7 Sentiment Leading to Breakouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6664a36c-cb14-40ce-905b-d0eb6529df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 17:31:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+----------------------+---------------------+\n",
      "|               DATE|         sentiment|next_day_crypto_return|next_day_stock_return|\n",
      "+-------------------+------------------+----------------------+---------------------+\n",
      "|2024-03-13 00:00:00|0.3234941020785715|                  NULL|                 NULL|\n",
      "+-------------------+------------------+----------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/10 17:31:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# Big Next-Day Jumps After Sentiment Spikes\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "   DATE,\n",
    "   sentiment,\n",
    "   LEAD(((c_close - c_open)/c_open)*100, 1) OVER (ORDER BY DATE) AS next_day_crypto_return,\n",
    "   LEAD(((s_close - s_open)/s_open)*100, 1) OVER (ORDER BY DATE) AS next_day_stock_return\n",
    "FROM transformed_data\n",
    "WHERE sentiment > 0.3\n",
    "ORDER BY DATE\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d850a5-3d0a-4522-9ea3-5a0d1304685f",
   "metadata": {},
   "source": [
    "#### 8.8 Big Move Days with Sentiment Neutrality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39674e4c-06c7-49cd-8932-c6afd01dd1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------+-----------+\n",
      "|DATE|sentiment|stock_move|crypto_move|\n",
      "+----+---------+----------+-----------+\n",
      "+----+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Detect Market Movers Without Sentiment Spike\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE,\n",
    "  sentiment,\n",
    "  ((s_close - s_open)/s_open)*100 AS stock_move,\n",
    "  ((c_close - c_open)/c_open)*100 AS crypto_move\n",
    "FROM transformed_data\n",
    "WHERE ABS(sentiment) < 0.05 AND (ABS((s_close - s_open)/s_open) > 3 OR ABS((c_close - c_open)/c_open) > 5)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150fec0-21cf-4d8d-9d0f-42ef7ff18084",
   "metadata": {},
   "source": [
    "## Insights from Combined Analysis\n",
    "\n",
    "\n",
    "### 8.1 Price Comparison Between Stocks & Crypto\n",
    "\n",
    "- Crypto markets show **greater daily volatility** compared to stock markets.\n",
    "- Even on relatively flat stock days, crypto often exhibits **larger swings**, reinforcing the high-risk/high-reward profile of crypto assets.\n",
    "\n",
    "### 8.2 Sentiment vs Daily Returns\n",
    "\n",
    "- There appears to be a **moderate positive correlation** between sentiment polarity and market returns.\n",
    "- However, the relationship is **not always consistent**, especially for stocks.\n",
    "\n",
    "### 8.3 High Sentiment but Prices Dropped\n",
    "\n",
    "- On **2024-03-13**, sentiment was high (0.323), yet stock prices **fell**, and crypto rose modestly.\n",
    "- This shows **optimistic sentiment does not always lead to market gains**, possibly due to overhype or delayed reactions.\n",
    "\n",
    "### 8.4 Low Sentiment but Prices Rose\n",
    "\n",
    "- Several dates (e.g., 2024-02-01, 2024-02-26) saw **negative or neutral sentiment but strong market gains**.\n",
    "- Suggests **market rebounds or hidden drivers** that sentiment analysis may miss.\n",
    "\n",
    "### 8.5 Weekly Avg Sentiment & Market Return\n",
    "\n",
    "- Some weeks with **positive sentiment** align with higher returns (Week 6, 7, 46).\n",
    "- But some weeks show **positive sentiment with negative returns**, reinforcing that **sentiment alone isn't sufficient**.\n",
    "\n",
    "### 8.6 Lagged Sentiment vs Future Returns\n",
    "\n",
    "- No clear or strong predictive power of sentiment on **next-day returns**.\n",
    "- Some high-sentiment days are followed by losses (e.g., crypto -5%), suggesting markets may **already price in sentiment**.\n",
    "\n",
    "### 8.7 Sentiment Spikes Leading to Breakouts\n",
    "\n",
    "- Limited evidence that **sentiment spikes lead to breakouts**.\n",
    "- In fact, after high sentiment days, next-day returns were either missing or inconsistent — possibly due to **data gaps** or **weak lag correlation**.\n",
    "\n",
    "### 8.8 Big Move Days with Sentiment Neutrality\n",
    "\n",
    "- No results found.\n",
    "- Suggests that **major market moves are typically accompanied by stronger sentiment**, reinforcing the link between news and volatility.\n",
    "\n",
    "## Final Conclusion\n",
    "\n",
    "The analysis shows:\n",
    "- **Crypto markets** are more volatile than stocks.\n",
    "- **Sentiment is partially correlated** with market returns — especially crypto — but **not reliably predictive**.\n",
    "- There are **exceptions** where sentiment and price movement diverge.\n",
    "- Sentiment analysis adds **context but not certainty** to market prediction — combining it with technical/volume data may improve models.\n",
    "\n",
    "This end-to-end querying builds a **360-degree view** of how public mood interacts with price behavior across asset classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede58257-5689-4dd2-8025-65d5000a531a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
