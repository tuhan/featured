{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d60428c3-1774-40a3-b303-0b8b2386dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75305410-fb2c-4b8f-8ee5-33392d2b40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Set the API key in the environment\n",
    "os.environ[\"POSTGRES_USERNAME\"] = \"\"\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = \"\"\n",
    "os.environ[\"POSTGRES_SCHEMA\"] = \"\"\n",
    "\n",
    "os.environ['MONGODB_PASSWORD'] = 'io8OKNKlqOk79hLv'\n",
    "os.environ['POLYGON_API_KEY'] = '25ilKx91RSsS8wO7yGQO66OmNR5CxoIu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96c9d5b-3d1b-453d-ba05-e2f96e779711",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MongoClient\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54695103-65d0-4635-b918-5dda81803138",
   "metadata": {},
   "source": [
    "## Database Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ae34b-c091-4fd9-8759-c2ca4e0a9bf5",
   "metadata": {},
   "source": [
    "### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7187c70-ff66-4faf-828e-2ab4319f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create PostgreSQL connection string\n",
    "pg_conn_string = f\"postgresql+psycopg2://{os.getenv('POSTGRES_USERNAME')}:{os.getenv('POSTGRES_PASSWORD')}@{\"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\"}:{5432}/{\"postgres\"}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "pg_engine = create_engine(pg_conn_string, connect_args={\"options\": f\"-c search_path={os.getenv('POSTGRES_SCHEMA')}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333649a-df91-4bed-b571-ac908c9f47a4",
   "metadata": {},
   "source": [
    "### Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fa844ae-e628-4bb6-837e-4186fc6c9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/?retryWrites=true&w=majority&appName=ucl-de\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['ucl-de']\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca7a04-e79b-444b-8bad-a3db5dd5dd7c",
   "metadata": {},
   "source": [
    "## Stock Market Data - SQL/DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4113c96d-7f6d-49fc-a667-08cff8145cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not connect to server: Operation timed out\n\tIs the server running on host \"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\" (18.132.143.129) and accepting\n\tTCP/IP connections on port 5432?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3302\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3282\u001b[0m \n\u001b[1;32m   3283\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3300\u001b[0m \n\u001b[1;32m   3301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:621\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Operation timed out\n\tIs the server running on host \"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\" (18.132.143.129) and accepting\n\tTCP/IP connections on port 5432?\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m df_stock\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to PostgreSQL as 'stock_data' table\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m df_stock\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_data\u001b[39m\u001b[38;5;124m'\u001b[39m, pg_engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[1;32m     31\u001b[0m df_stock\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3089\u001b[0m     name,\n\u001b[1;32m   3090\u001b[0m     con,\n\u001b[1;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   3098\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:841\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m    843\u001b[0m         frame,\n\u001b[1;32m    844\u001b[0m         name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    854\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:906\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema, need_transaction)\n\u001b[1;32m    908\u001b[0m adbc \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc_driver_manager.dbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc\u001b[38;5;241m.\u001b[39mConnection):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:1636\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[0;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[0;32m-> 1636\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mconnect())\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3278\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3257\u001b[0m \n\u001b[1;32m   3258\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3275\u001b[0m \n\u001b[1;32m   3276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_cls(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:148\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 148\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    149\u001b[0m             err, dialect, engine\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2442\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2441\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2444\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    148\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    149\u001b[0m             err, dialect, engine\n\u001b[1;32m    150\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3302\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3282\u001b[0m \n\u001b[1;32m   3283\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3300\u001b[0m \n\u001b[1;32m   3301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    710\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:621\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not connect to server: Operation timed out\n\tIs the server running on host \"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\" (18.132.143.129) and accepting\n\tTCP/IP connections on port 5432?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# Getting Stock Data for S&P ETF & Top 10 Companies for 2024-01-01 to 2024-12-31\n",
    "# Define the ticker symbols\n",
    "tickers = ['SPY', 'AAPL', 'MSFT', 'NVDA', 'AMZN', 'META', 'GOOGL', 'TSLA', 'AVGO', 'GOOG', 'BRK-B']\n",
    "\n",
    "# Download historical data for 2024\n",
    "df_stock = yf.download(tickers, start=\"2024-01-01\", end=\"2024-12-31\")\n",
    "\n",
    "# Reset the index to make the date a column and flatten the MultiIndex columns\n",
    "df_stock.columns = ['_'.join(col).strip() for col in df_stock.columns.to_flat_index()]\n",
    "df_stock.reset_index(inplace=True)\n",
    "\n",
    "# Unpivot the DataFrame while keeping columns for 'Date' and 'Symbol'\n",
    "df_stock = df_stock.melt(id_vars=['Date'], var_name='Symbol_Price', value_name='Value')\n",
    "\n",
    "# Extract 'Symbol' and 'Price' from the 'Symbol_Price' column\n",
    "df_stock[['Price', 'Symbol']] = df_stock['Symbol_Price'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the 'Symbol_Price' column\n",
    "df_stock.drop(columns=['Symbol_Price'], inplace=True)\n",
    "\n",
    "# Pivot the table to create a wide format with columns for High, Low, Open, Close, Volume\n",
    "df_stock = df_stock.pivot_table(index=['Date', 'Symbol'], columns='Price', values='Value', aggfunc='first')\n",
    "\n",
    "# Reset the index to flatten the result\n",
    "df_stock.reset_index(inplace=True)\n",
    "\n",
    "# Save the DataFrame to PostgreSQL as 'stock_data' table\n",
    "df_stock.to_sql('stock_data', pg_engine, if_exists='replace', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e54d1a-8b5a-44ef-a703-d0cdabad9e90",
   "metadata": {},
   "source": [
    "## Crypto Data - NoSQL/JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ff843d9a-5732-4728-bf61-ff01001f38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coin_data(coin_names):\n",
    "    for coin_name in coin_names:\n",
    "        # Base URL for Polygon.io API\n",
    "        url = 'https://api.polygon.io/v2/aggs/ticker/X:'+coin_name+'USD/range/1/day/2024-01-01/2024-12-31'\n",
    "        \n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url, params={'apiKey': os.getenv('POLYGON_API_KEY')})\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(coin_name)\n",
    "            print(data['results'][0])\n",
    "            # Extract the 'results' JSON and rename fields\n",
    "            data_to_save = [{\n",
    "                'volume': result['v'],\n",
    "                'volume_weighted': result['vw'],\n",
    "                'open': result['o'],\n",
    "                'close': result['c'],\n",
    "                'high': result['h'],\n",
    "                'low': result['l'],\n",
    "                'timestamp': pd.to_datetime(result['t'], unit='ms'),\n",
    "                'num_trades': result['n'],\n",
    "                'coin_name': coin_name  # Add the coin_name field\n",
    "            } for result in data['results']]     \n",
    "\n",
    "            # Connect to MongoDB and insert the documents\n",
    "            collection = db['crypto_data']\n",
    "            collection.insert_many(data_to_save)\n",
    "            print(\"Documents inserted successfully.\")\n",
    "        else:\n",
    "            print(f\"Error fetching data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7fbb4-18d3-4aca-a2ac-a861f5a3730f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Note:</strong> Only five (5) requests a minute so two loops for 10.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9e4d9ecf-f34c-4c40-b9ce-cc1b5a68538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOGE\n",
      "{'v': 151978174.98105866, 'vw': 0.0907, 'o': 0.0894535, 'c': 0.09202, 'h': 0.092192, 'l': 0.0885, 't': 1704067200000, 'n': 22997}\n",
      "Documents inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "coin_names_1 = {\"BTC\", \"ETH\", \"XRP\", \"SOL\", \"DOGE\"}\n",
    "get_coin_data(coin_names_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "be2a342e-36fd-4870-96cc-a0bbe9b9b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRX\n",
      "{'v': 3571715.355314876, 'vw': 0.1074, 'o': 0.10782, 'c': 0.107762, 'h': 0.1085, 'l': 0.10611, 't': 1704067200000, 'n': 1468}\n",
      "Documents inserted successfully.\n",
      "AVAX\n",
      "{'v': 1135998.6278387264, 'vw': 39.9644, 'o': 38.56, 'c': 41.97, 'h': 42.07, 'l': 38.03, 't': 1704067200000, 'n': 41986}\n",
      "Documents inserted successfully.\n",
      "XLM\n",
      "{'v': 47408847.258499086, 'vw': 0.1298, 'o': 0.129153, 'c': 0.131996, 'h': 0.13247, 'l': 0.127307, 't': 1704067200000, 'n': 18514}\n",
      "Documents inserted successfully.\n",
      "ADA\n",
      "{'v': 29513903.584032178, 'vw': 0.6066, 'o': 0.5935, 'c': 0.6236, 'h': 0.6244, 'l': 0.5903, 't': 1704067200000, 'n': 33605}\n",
      "Documents inserted successfully.\n",
      "DOT\n",
      "{'v': 1423805.1920128518, 'vw': 8.411, 'o': 8.206, 'c': 8.598, 'h': 8.6372, 'l': 8.06, 't': 1704067200000, 'n': 23814}\n",
      "Documents inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "coin_names_2 = {\"ADA\", \"TRX\", \"XLM\", \"AVAX\", \"SHIB\"}\n",
    "get_coin_data(coin_names_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab12f2-baca-4db7-a7b2-a4645111a299",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c34fdc-18c8-48a0-8e07-9773849815b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Code Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab955f01-abea-42e0-9a26-c25ce5b11a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'crypto_posts.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open and read the JSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrypto_posts.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize an empty list to store the formatted data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'crypto_posts.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('crypto_posts.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize an empty list to store the formatted data\n",
    "crypto_posts = []\n",
    "\n",
    "# Get the keys of the timestamp and post data dynamically\n",
    "timestamp_keys = data.get('timestamp', {}).keys()\n",
    "post_keys = data.get('post', {}).keys()\n",
    "\n",
    "# We will assume both 'timestamp' and 'post' have the same keys\n",
    "# Loop through all available keys\n",
    "for key in timestamp_keys:\n",
    "    # Dynamically create a dictionary combining values from timestamp and post for each key\n",
    "    crypto_posts.append({\n",
    "        **{field: data[field].get(key, '') for field in data if isinstance(data[field], dict)},\n",
    "    })\n",
    "\n",
    "# Print the structured output\n",
    "# print(json.dumps(crypto_posts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b289faf-96e1-43a6-b312-b13424dbee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MongoDB connection\n",
    "# Other parts already set above\n",
    "collection = db['crypto_posts']  # Replace with your collection name\n",
    "\n",
    "# Insert the data into the collection\n",
    "collection.insert_many(crypto_posts)\n",
    "\n",
    "# Check if data is saved by querying the collection\n",
    "saved_data = collection.find().limit(5)  # Get the first 5 documents for verification\n",
    "\n",
    "# Print out the saved data\n",
    "for document in saved_data:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c46e2-d0cb-456a-b89c-c591c7de97f7",
   "metadata": {},
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9788d448-f71a-4dd6-b80c-11a3961b9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "mongo_package_name = \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\"\n",
    "postgress_package_name = \"org.postgresql:postgresql:42.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284ceb8a-2553-4d24-8278-55cddd6fc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.5.4-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d45a444e-0857-4b20-a24c-8c4bc3b66070;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.3.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 799ms :: artifacts dl 104ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.postgresql#postgresql;42.3.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d45a444e-0857-4b20-a24c-8c4bc3b66070\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/26ms)\n",
      "25/03/10 10:50:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\", f\"{postgress_package_name},{mongo_package_name}\") \\\n",
    "    .appName(\"PostgresMongo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4f917-6333-400e-8a31-891eace66b72",
   "metadata": {},
   "source": [
    "### Getting from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50460bc1-a70e-492e-99a5-cf9aae40ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "|               Date|Symbol|             Close|              High|               Low|              Open|   Volume|\n",
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "|2024-01-02 00:00:00|  AAPL|184.53208923339844|187.31538170646215|182.79253333369908|186.03307200647276|8.24887E7|\n",
      "|2024-01-02 00:00:00|  AMZN|149.92999267578125| 152.3800048828125|148.38999938964844| 151.5399932861328|4.73394E7|\n",
      "|2024-01-02 00:00:00|  AVGO|107.09550476074219|108.73541136554675|106.27752002980789|107.76054315701123| 2.8831E7|\n",
      "|2024-01-02 00:00:00| BRK-B| 362.4599914550781|362.57000732421875|355.94000244140625|356.32000732421875|4737000.0|\n",
      "|2024-01-02 00:00:00|  GOOG|139.06033325195312|    140.1115639594|137.24685727343498|139.10019855495605|2.00719E7|\n",
      "+-------------------+------+------------------+------------------+------------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL connection details\n",
    "pg_url = f\"jdbc:postgresql://uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com:5432/postgres\"\n",
    "pg_properties = {\n",
    "    \"user\": os.getenv(\"POSTGRES_USERNAME\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"searchpath\": os.getenv(\"POSTGRES_SCHEMA\")  # Optional, specify schema if necessary\n",
    "}\n",
    "\n",
    "# Define the table name\n",
    "table_name = \"stock_data\"  # Replace with your table name\n",
    "\n",
    "# Form the SQL query\n",
    "query = f\"SELECT * FROM {os.getenv(\"POSTGRES_SCHEMA\")}.{table_name}\"\n",
    "\n",
    "# Load data from PostgreSQL into Spark DataFrame\n",
    "df_stocks = spark.read.jdbc(url=pg_url, table=f\"({query}) as query\", properties=pg_properties)\n",
    "\n",
    "# Show the first 5 rows of the dataframe\n",
    "df_stocks.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4d94c-5a17-44f2-9047-f1188fe6827f",
   "metadata": {},
   "source": [
    "### Getting from Mongo - Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a28cee8-8596-465c-902d-d0986584e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "| close|coin_name|  high|   low|num_trades|  open|          timestamp|            volume|volume_weighted|\n",
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "|110.11|      SOL|110.44|101.47|    108681| 101.7|2024-01-01 00:00:00| 1626237.539067202|       105.8227|\n",
      "|106.74|      SOL|117.03| 106.0|    200857| 109.9|2024-01-02 00:00:00|2735152.6783066373|       111.1942|\n",
      "| 98.59|      SOL|110.04|  71.0|    276745|106.77|2024-01-03 00:00:00|4241949.4304016875|        99.1378|\n",
      "|105.01|      SOL|108.26| 96.67|    156567| 98.57|2024-01-04 00:00:00|2364126.5787030575|       102.6787|\n",
      "|100.02|      SOL|105.57| 95.33|    155260|105.01|2024-01-05 00:00:00|2027948.8000170968|        99.8606|\n",
      "+------+---------+------+------+----------+------+-------------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_crypto = spark.read.format(\"mongo\").option(\"uri\", \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/ucl-de.crypto_data?retryWrites=true&w=majority\").load()\n",
    "df_crypto = df_crpyto.drop(\"_id\")\n",
    "df_crypto.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15fee1-f040-4fd9-859f-a3f0d1e56669",
   "metadata": {},
   "source": [
    "### Getting from Mongo - Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3bcd11d-46ae-4e50-82df-5ff67ec5d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "|        cleaned_post|    polarity|                post|             subject|subjectivity|subsection| timestamp|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "|You've been holdi...|0.1353333333|You've been holdi...|Has Bitcoin met y...|0.5226666667|       BTC|2024-11-05|\n",
      "|Bitcoin has indee...|0.1534090909|Bitcoin has indee...|Has Bitcoin met y...|0.5629734848|       BTC|2024-11-05|\n",
      "|I would say Bitco...|0.4083333333|I would say Bitco...|Has Bitcoin met y...|0.3444444444|       BTC|2024-11-05|\n",
      "|My question to yo...|0.0798611111|Quote from: David...|Has Bitcoin met y...|0.5534722222|       BTC|2024-11-05|\n",
      "|You've been holdi...|0.0408333333|Quote from: David...|Has Bitcoin met y...|0.3734259259|       BTC|2024-11-05|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posts = spark.read.format(\"mongo\").option(\"uri\", \"mongodb+srv://ucl-de:\"+os.getenv('MONGODB_PASSWORD')+\"@ucl-de.auvdj.mongodb.net/ucl-de.crypto_posts?retryWrites=true&w=majority\").load()\n",
    "df_posts = df_posts.drop(\"_id\")\n",
    "df_posts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ce78684-b26d-4af3-ba63-d8e65cd860b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "|        cleaned_post|    polarity|                post|             subject|subjectivity|subsection|          timestamp|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "|You've been holdi...|0.1353333333|You've been holdi...|Has Bitcoin met y...|0.5226666667|       BTC|2024-11-05 00:00:00|\n",
      "|Bitcoin has indee...|0.1534090909|Bitcoin has indee...|Has Bitcoin met y...|0.5629734848|       BTC|2024-11-05 00:00:00|\n",
      "|I would say Bitco...|0.4083333333|I would say Bitco...|Has Bitcoin met y...|0.3444444444|       BTC|2024-11-05 00:00:00|\n",
      "|My question to yo...|0.0798611111|Quote from: David...|Has Bitcoin met y...|0.5534722222|       BTC|2024-11-05 00:00:00|\n",
      "|You've been holdi...|0.0408333333|Quote from: David...|Has Bitcoin met y...|0.3734259259|       BTC|2024-11-05 00:00:00|\n",
      "+--------------------+------------+--------------------+--------------------+------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cast 'timestamp' column to TIMESTAMP type if it's in string format\n",
    "df_posts = df_posts.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "# Now show the updated dataframe\n",
    "df_posts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86680d55-6f1d-4a36-a3ac-44a035972eae",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875d9e1-090b-48ec-bc4a-089f227eb638",
   "metadata": {},
   "source": [
    "### 1. Understand Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ae081f-f5a6-4b78-90c0-1b42fe8f03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.createOrReplaceTempView(\"stocks\")\n",
    "df_crypto.createOrReplaceTempView(\"crypto\")\n",
    "df_posts.createOrReplaceTempView(\"posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6df7d6d9-30cb-4a29-a2f3-37248ff54785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|      2761|2024-01-02 00:00:00|2024-12-30 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(Date) AS start_date,\n",
    "        MAX(Date) AS end_date\n",
    "    FROM stocks\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1045366-499d-4e55-b2e7-e079e1f8b77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|     40626|2024-01-01 00:00:00|2024-12-31 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(timestamp) AS start_date,\n",
    "        MAX(timestamp) AS end_date\n",
    "    FROM crypto\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ef2fdcf-63d6-4e7f-a00e-748eb62aa5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|total_rows|         start_date|           end_date|\n",
      "+----------+-------------------+-------------------+\n",
      "|      1526|2010-10-19 00:00:00|2024-12-30 00:00:00|\n",
      "+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(CAST(timestamp AS TIMESTAMP)) AS start_date,\n",
    "        MAX(CAST(timestamp AS TIMESTAMP)) AS end_date\n",
    "    FROM posts\n",
    "    WHERE timestamp IS NOT NULL\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
